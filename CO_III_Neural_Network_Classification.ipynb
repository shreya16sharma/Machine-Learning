{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of CO III  Neural_Network_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreya16sharma/Machine-Learning/blob/main/CO_III_Neural_Network_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhPEM4IUoDKA"
      },
      "source": [
        "# Joint Online Faculty Development programme on Deep Learning (Parallel Architecture) Aug 23 â€“ Sep 3 , 2021\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpJe0cAaoG98"
      },
      "source": [
        "# Tutorial 3: Neural Network Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIT7QrK2PwdM"
      },
      "source": [
        "Dataset: [Pima Indian Diabetes Dataset](https://data.world/data-society/pima-indians-diabetes-database#)\n",
        "\n",
        "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective is to predict based on diagnostic measurements whether a patient has diabetes.\n",
        "\n",
        "Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
        "\n",
        "Attributes of PIMA dataset:\n",
        "\n",
        "**Pregnancies**: Number of times pregnant\n",
        "\n",
        "**Glucose**: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "\n",
        "**BloodPressure**: Diastolic blood pressure (mm Hg)\n",
        "\n",
        "**SkinThickness**: Triceps skin fold thickness (mm)\n",
        "\n",
        "**Insulin**: 2-Hour serum insulin (mu U/ml)\n",
        "\n",
        "**BMI**: Body mass index (weight in kg/(height in m)^2)\n",
        "\n",
        "**DiabetesPedigreeFunction**: Diabetes pedigree function\n",
        "\n",
        "**Age**: Age (years)\n",
        "\n",
        "**Outcome**: Class variable (0 or 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIAgs3sTY712"
      },
      "source": [
        "**1. Mount the Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrZg_G5MQ4L5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f46f0a-7dc7-4cf9-d2b0-a917484bbb52"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqAhYoWHZAwg"
      },
      "source": [
        "**2. Move to the place where data resides**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjgG_3CiP4eQ",
        "outputId": "49f1444a-05e4-4c69-abcc-0bc3be2a0b2a"
      },
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "S-KhHH_xATY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c357e1e5-0f32-4608-af31-7562d33d726b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Acropolis Institute of Technology.pptx'\n",
            "'ADAfactorialknapsack(CO-33).pdf'\n",
            "'ADAquicksort(CO-33).docx'\n",
            "'Admit Card.pdf'\n",
            "'Agile Software Development Framework- Scrum.gslides'\n",
            "'BASIC COMMANDS WITH PHP EXAMPLES (1).gdoc'\n",
            "'BASIC COMMANDS WITH PHP EXAMPLES.gdoc'\n",
            " cert-1014-21445798.jpg\n",
            " Classroom\n",
            "'Colab Notebooks'\n",
            "'compiler design (unit-1).pdf'\n",
            "'Cookies and Session.gdoc'\n",
            "'covid 19 pledge.docx'\n",
            "'CS2303 Theory of Computation _21308 may2013.gdoc'\n",
            " cs-504-a-internet-and-web-technology-jun-2020.gdoc\n",
            " cs-504-internet-and-web-technology-nov-2019.gdoc\n",
            "'cs-505-theory-of-computation-dec-2011 (1).gdoc'\n",
            " cs-505-theory-of-computation-dec-2011.gdoc\n",
            "'cs-505-theory-of-computation-dec-2013 (1).gdoc'\n",
            " cs-505-theory-of-computation-dec-2013.gdoc\n",
            " CSS.gdoc\n",
            " Cybersecurity_Foundation_Student_Certificate.pdf\n",
            "'cyber security.gslides'\n",
            "'Cyber Security Training (CO-33).gdoc'\n",
            "'Cyber Security Training.gslides'\n",
            " cybrary-cert-introduction-to-it-and-cybersecurity.pdf\n",
            "'Data Analytics (CO-33).gslides'\n",
            "'dbms lab work (CO-33) - Bar chart 1.gsheet'\n",
            "'dbms ppt.gslides'\n",
            " desktop\n",
            " diabetes.csv\n",
            "'Getting started.pdf'\n",
            "'HTML - Forms and frames.gdoc'\n",
            "'HTML Marquee tag.gdoc'\n",
            "'IBM AI0101EN Certificate _ edX.pdf'\n",
            "'IBM DS0101EN Certificate _ edX (1).pdf'\n",
            "'IBM DS0101EN Certificate _ edX.pdf'\n",
            "'IBM PY0101EN Certificate _ edX.pdf'\n",
            " IMG_20200819_150914.jpg\n",
            " IMG_20200819_150951.jpg\n",
            " IMG_20200819_151648.jpg\n",
            " IMG_20210724_134352.jpg\n",
            " IMG-20210831-WA0007.jpg\n",
            " IMG-20211110-WA0016.jpg\n",
            "'Introduction to ethical hacking.pdf'\n",
            "'IWT HTML - Formatting,Fonts and Links.gdoc'\n",
            "'IWT HTML - List and tables.gdoc'\n",
            "'IWT Internet and WWW,HTTP.gdoc'\n",
            "'IWT  Web Design.gdoc'\n",
            "'IWT Web.gdoc'\n",
            "'IWT  Website.gdoc'\n",
            " javaconsole.gdoc\n",
            " JavaScript.gdoc\n",
            "'LinuxFoundationX LFS101x Certificate _ edX.pdf'\n",
            "'Linux _Lab-CS505 File Format.gdoc'\n",
            "'meetali jain (CO-33) ADA .pdf'\n",
            "'Meetali Jain (CO-33) CSO .pdf'\n",
            "'Meetali Jain (CO-33) DA.gdoc'\n",
            "'Meetali Jain(CO-33).gslides'\n",
            "'Meetali jain resume (1).pdf'\n",
            "'Meetali jain resume.pdf'\n",
            "'minor project'\n",
            "'Novelty test.docx'\n",
            " Object.gdoc\n",
            " Parent_AFD_2290977_2712202016056374.pdf\n",
            " PC-E\n",
            " petrol_consumption.csv\n",
            " PHP.gdoc\n",
            " pythonhackerrank.png\n",
            " Screenshot_2021_0531_142941.jpg\n",
            " Screenshot_20210806_115617.jpg\n",
            " Screenshot_20210915_112918.jpg\n",
            " Screenshot_20211005_162803.jpg\n",
            " Screenshot_20220127_131540.jpg\n",
            " screenshot.jpeg\n",
            " semester-5\n",
            " semester-6\n",
            " Student_AFD_2290977_2712202016056233.pdf\n",
            " TOC_Practical_assessment_format.gdoc\n",
            "'Untitled presentation (1).gslides'\n",
            "'Untitled presentation.gslides'\n",
            "'UPDATED DBMS PPT (1).gslides'\n",
            "'USMx ENES608.3 Certificate _ edX.pdf'\n",
            "'UWashingtonX CYB003x Certificate _ edX.pdf'\n",
            "'WhatsApp Image 2021-10-04 at 5.09.45 PM.jpeg'\n",
            " WM255LS5LN.pdf\n",
            " XML.gdoc\n",
            "'XML Validation.gdoc'\n",
            " XML-XSD.gdoc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKvfswsOZLUB"
      },
      "source": [
        "**3. Read the dataset from CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "32nNonRSSaQq",
        "outputId": "9228e47b-5a0f-4729-e173-a84affcb623c"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('diabetes.csv')\n",
        "data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "5            5      116             74              0        0  25.6   \n",
              "6            3       78             50             32       88  31.0   \n",
              "7           10      115              0              0        0  35.3   \n",
              "8            2      197             70             45      543  30.5   \n",
              "9            8      125             96              0        0   0.0   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  \n",
              "5                     0.201   30        0  \n",
              "6                     0.248   26        1  \n",
              "7                     0.134   29        0  \n",
              "8                     0.158   53        1  \n",
              "9                     0.232   54        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-045bbfa2-6a29-420e-a5b0-17ba5a16f344\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>78</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.248</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.3</td>\n",
              "      <td>0.134</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>197</td>\n",
              "      <td>70</td>\n",
              "      <td>45</td>\n",
              "      <td>543</td>\n",
              "      <td>30.5</td>\n",
              "      <td>0.158</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>125</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-045bbfa2-6a29-420e-a5b0-17ba5a16f344')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-045bbfa2-6a29-420e-a5b0-17ba5a16f344 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-045bbfa2-6a29-420e-a5b0-17ba5a16f344');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrslDLESShr7",
        "outputId": "5db7a844-bebc-4c4f-a40a-2d386fb8c861"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
              "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLElehZ-Skgq",
        "outputId": "3024b00d-b0f0-4957-8d3a-54a96805a15f"
      },
      "source": [
        "data.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HnZxGc4ZQlf"
      },
      "source": [
        "**4. Store the data into input feature and label variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPfA5BF0Sm4R",
        "outputId": "f172b9be-7e7a-4c6b-c3a4-3f6e9296a25e"
      },
      "source": [
        "dataset= data.values\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdPZerNUZV4Q"
      },
      "source": [
        "**5. Data Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM4g3T1fWri-",
        "outputId": "e1bfe19e-5830-4897-98b6-b00133b3bcfe"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1B5x8C0ZY-e"
      },
      "source": [
        "**6. One-hot vector conversion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWPUAnA-XNd8",
        "outputId": "ecfdc7c7-6002-4e2b-caec-7c12af3e69e2"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "encoded_y = np_utils.to_categorical(Y)\n",
        "encoded_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeJWmMxjZbgo"
      },
      "source": [
        "**7. Split the dataset into training, testing and validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BqXnV1FXYIV",
        "outputId": "701c0324-ad2a-4352-9d44-96e7b1206041"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_training, X_testing, Y_training, Y_testing = train_test_split(X_scale, encoded_y, test_size=0.4, random_state=10)\n",
        "X_training, X_valid, Y_training, Y_valid = train_test_split(X_training, Y_training, test_size=0.4, random_state=10)\n",
        "print(len(X_training))\n",
        "print(len(X_testing))\n",
        "print(len(X_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "276\n",
            "308\n",
            "184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH9IZizVZfKB"
      },
      "source": [
        "**8. Model Creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNfmvbMOXeku",
        "outputId": "2ec209cd-4546-4a0a-fb28-584ac983ddb2"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_shape=(8,), activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()   #gives a summary of the model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_25 (Dense)            (None, 12)                108       \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 10)                90        \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 2)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 324\n",
            "Trainable params: 324\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYxZHI_EZiEF"
      },
      "source": [
        "**9. Model Compile**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plF2qlxwXiIY"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "opt=optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8VrUFVQZkNd"
      },
      "source": [
        "**10. Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you have 1000 training examples, and your batch size is  500, then it will take 2 iterations to complete 1 epoch."
      ],
      "metadata": {
        "id": "08Ul5lN90_Sp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhDZ8yPhXrs0",
        "outputId": "e556e621-21f3-4288-ba45-37825f944248"
      },
      "source": [
        "hist = model.fit(X_training, Y_training,batch_size=16,  epochs=1000, validation_data=(X_valid,Y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "18/18 [==============================] - 1s 15ms/step - loss: 0.0298 - accuracy: 0.9855 - val_loss: 4.3426 - val_accuracy: 0.6902\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0331 - accuracy: 0.9855 - val_loss: 4.3317 - val_accuracy: 0.6902\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 0.9891 - val_loss: 4.4285 - val_accuracy: 0.7011\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 0.9891 - val_loss: 4.4118 - val_accuracy: 0.6957\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 0.9855 - val_loss: 4.2695 - val_accuracy: 0.6793\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0311 - accuracy: 0.9891 - val_loss: 4.3115 - val_accuracy: 0.6902\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 0.9891 - val_loss: 4.4058 - val_accuracy: 0.6957\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.9891 - val_loss: 4.4681 - val_accuracy: 0.6902\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 0.9855 - val_loss: 4.4887 - val_accuracy: 0.6902\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0282 - accuracy: 0.9855 - val_loss: 4.5135 - val_accuracy: 0.6957\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 0.9855 - val_loss: 4.5400 - val_accuracy: 0.6957\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0281 - accuracy: 0.9891 - val_loss: 4.5415 - val_accuracy: 0.6902\n",
            "Epoch 13/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0281 - accuracy: 0.9891 - val_loss: 4.5521 - val_accuracy: 0.6902\n",
            "Epoch 14/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0278 - accuracy: 0.9891 - val_loss: 4.5944 - val_accuracy: 0.6957\n",
            "Epoch 15/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9855 - val_loss: 4.6059 - val_accuracy: 0.6957\n",
            "Epoch 16/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 0.9891 - val_loss: 4.5932 - val_accuracy: 0.6902\n",
            "Epoch 17/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0281 - accuracy: 0.9891 - val_loss: 4.5894 - val_accuracy: 0.6848\n",
            "Epoch 18/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0286 - accuracy: 0.9891 - val_loss: 4.5287 - val_accuracy: 0.6902\n",
            "Epoch 19/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 0.9855 - val_loss: 4.5914 - val_accuracy: 0.6902\n",
            "Epoch 20/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0278 - accuracy: 0.9855 - val_loss: 4.6833 - val_accuracy: 0.6902\n",
            "Epoch 21/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9855 - val_loss: 4.6114 - val_accuracy: 0.6848\n",
            "Epoch 22/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0279 - accuracy: 0.9891 - val_loss: 4.6056 - val_accuracy: 0.6957\n",
            "Epoch 23/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9891 - val_loss: 4.6636 - val_accuracy: 0.6957\n",
            "Epoch 24/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0274 - accuracy: 0.9891 - val_loss: 4.6837 - val_accuracy: 0.6957\n",
            "Epoch 25/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9891 - val_loss: 4.6815 - val_accuracy: 0.6957\n",
            "Epoch 26/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0274 - accuracy: 0.9855 - val_loss: 4.7175 - val_accuracy: 0.7011\n",
            "Epoch 27/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0274 - accuracy: 0.9855 - val_loss: 4.7322 - val_accuracy: 0.6957\n",
            "Epoch 28/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0272 - accuracy: 0.9891 - val_loss: 4.7229 - val_accuracy: 0.6957\n",
            "Epoch 29/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0274 - accuracy: 0.9891 - val_loss: 4.7312 - val_accuracy: 0.6902\n",
            "Epoch 30/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0275 - accuracy: 0.9891 - val_loss: 4.7378 - val_accuracy: 0.6902\n",
            "Epoch 31/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0273 - accuracy: 0.9891 - val_loss: 4.7223 - val_accuracy: 0.6848\n",
            "Epoch 32/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9891 - val_loss: 4.6936 - val_accuracy: 0.6902\n",
            "Epoch 33/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0275 - accuracy: 0.9891 - val_loss: 4.7345 - val_accuracy: 0.7011\n",
            "Epoch 34/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 0.9891 - val_loss: 4.7937 - val_accuracy: 0.6902\n",
            "Epoch 35/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 0.9891 - val_loss: 4.8277 - val_accuracy: 0.6848\n",
            "Epoch 36/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0277 - accuracy: 0.9855 - val_loss: 4.8625 - val_accuracy: 0.6902\n",
            "Epoch 37/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0275 - accuracy: 0.9891 - val_loss: 4.7508 - val_accuracy: 0.6848\n",
            "Epoch 38/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0280 - accuracy: 0.9891 - val_loss: 4.7182 - val_accuracy: 0.6902\n",
            "Epoch 39/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0272 - accuracy: 0.9855 - val_loss: 4.7673 - val_accuracy: 0.6793\n",
            "Epoch 40/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9891 - val_loss: 4.8538 - val_accuracy: 0.6902\n",
            "Epoch 41/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.9928 - val_loss: 4.8847 - val_accuracy: 0.6902\n",
            "Epoch 42/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 0.9928 - val_loss: 4.8793 - val_accuracy: 0.6902\n",
            "Epoch 43/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0267 - accuracy: 0.9928 - val_loss: 4.9155 - val_accuracy: 0.6902\n",
            "Epoch 44/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 0.9928 - val_loss: 4.9267 - val_accuracy: 0.6902\n",
            "Epoch 45/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 0.9891 - val_loss: 4.9244 - val_accuracy: 0.6902\n",
            "Epoch 46/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 0.9891 - val_loss: 4.9609 - val_accuracy: 0.6902\n",
            "Epoch 47/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0274 - accuracy: 0.9891 - val_loss: 4.8269 - val_accuracy: 0.6848\n",
            "Epoch 48/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0281 - accuracy: 0.9855 - val_loss: 4.8602 - val_accuracy: 0.6848\n",
            "Epoch 49/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0277 - accuracy: 0.9891 - val_loss: 5.0330 - val_accuracy: 0.6902\n",
            "Epoch 50/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.9855 - val_loss: 4.9612 - val_accuracy: 0.6848\n",
            "Epoch 51/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0275 - accuracy: 0.9891 - val_loss: 4.7749 - val_accuracy: 0.6957\n",
            "Epoch 52/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 0.9891 - val_loss: 4.8273 - val_accuracy: 0.6957\n",
            "Epoch 53/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 0.9891 - val_loss: 4.8755 - val_accuracy: 0.7011\n",
            "Epoch 54/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.9891 - val_loss: 4.8868 - val_accuracy: 0.6957\n",
            "Epoch 55/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 0.9891 - val_loss: 4.9550 - val_accuracy: 0.6957\n",
            "Epoch 56/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0265 - accuracy: 0.9928 - val_loss: 4.9868 - val_accuracy: 0.6957\n",
            "Epoch 57/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0262 - accuracy: 0.9891 - val_loss: 4.9696 - val_accuracy: 0.6957\n",
            "Epoch 58/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0263 - accuracy: 0.9928 - val_loss: 5.0036 - val_accuracy: 0.6957\n",
            "Epoch 59/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9928 - val_loss: 4.9555 - val_accuracy: 0.6957\n",
            "Epoch 60/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9891 - val_loss: 4.9997 - val_accuracy: 0.7065\n",
            "Epoch 61/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9891 - val_loss: 5.0285 - val_accuracy: 0.7065\n",
            "Epoch 62/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 0.9928 - val_loss: 5.0148 - val_accuracy: 0.6957\n",
            "Epoch 63/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9891 - val_loss: 4.9931 - val_accuracy: 0.6957\n",
            "Epoch 64/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9928 - val_loss: 5.0730 - val_accuracy: 0.7011\n",
            "Epoch 65/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0262 - accuracy: 0.9891 - val_loss: 5.0533 - val_accuracy: 0.6902\n",
            "Epoch 66/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0261 - accuracy: 0.9928 - val_loss: 5.0575 - val_accuracy: 0.6902\n",
            "Epoch 67/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9928 - val_loss: 5.1005 - val_accuracy: 0.6902\n",
            "Epoch 68/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9928 - val_loss: 5.0974 - val_accuracy: 0.6902\n",
            "Epoch 69/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9891 - val_loss: 5.0526 - val_accuracy: 0.6902\n",
            "Epoch 70/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0262 - accuracy: 0.9891 - val_loss: 5.1333 - val_accuracy: 0.6957\n",
            "Epoch 71/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0258 - accuracy: 0.9928 - val_loss: 5.1534 - val_accuracy: 0.6902\n",
            "Epoch 72/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0258 - accuracy: 0.9928 - val_loss: 5.1734 - val_accuracy: 0.6902\n",
            "Epoch 73/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0258 - accuracy: 0.9928 - val_loss: 5.1214 - val_accuracy: 0.6793\n",
            "Epoch 74/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 0.9891 - val_loss: 5.0978 - val_accuracy: 0.6902\n",
            "Epoch 75/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0269 - accuracy: 0.9928 - val_loss: 5.1306 - val_accuracy: 0.6957\n",
            "Epoch 76/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 0.9891 - val_loss: 5.1440 - val_accuracy: 0.6957\n",
            "Epoch 77/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 0.9891 - val_loss: 5.1845 - val_accuracy: 0.6902\n",
            "Epoch 78/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9891 - val_loss: 4.9637 - val_accuracy: 0.6902\n",
            "Epoch 79/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 0.9891 - val_loss: 4.9219 - val_accuracy: 0.7011\n",
            "Epoch 80/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0327 - accuracy: 0.9855 - val_loss: 5.0775 - val_accuracy: 0.6957\n",
            "Epoch 81/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0288 - accuracy: 0.9891 - val_loss: 5.0437 - val_accuracy: 0.6793\n",
            "Epoch 82/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0306 - accuracy: 0.9855 - val_loss: 5.0507 - val_accuracy: 0.6848\n",
            "Epoch 83/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0268 - accuracy: 0.9891 - val_loss: 5.1697 - val_accuracy: 0.6902\n",
            "Epoch 84/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9891 - val_loss: 5.1913 - val_accuracy: 0.6848\n",
            "Epoch 85/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9891 - val_loss: 5.2175 - val_accuracy: 0.6902\n",
            "Epoch 86/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9891 - val_loss: 5.2260 - val_accuracy: 0.6902\n",
            "Epoch 87/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9891 - val_loss: 5.2382 - val_accuracy: 0.6902\n",
            "Epoch 88/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 0.9891 - val_loss: 5.2571 - val_accuracy: 0.6848\n",
            "Epoch 89/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0262 - accuracy: 0.9891 - val_loss: 5.2199 - val_accuracy: 0.6902\n",
            "Epoch 90/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0262 - accuracy: 0.9891 - val_loss: 5.2794 - val_accuracy: 0.6848\n",
            "Epoch 91/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 0.9891 - val_loss: 5.1717 - val_accuracy: 0.6902\n",
            "Epoch 92/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 0.9891 - val_loss: 5.2480 - val_accuracy: 0.6902\n",
            "Epoch 93/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0263 - accuracy: 0.9891 - val_loss: 5.2717 - val_accuracy: 0.6848\n",
            "Epoch 94/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0258 - accuracy: 0.9891 - val_loss: 5.2528 - val_accuracy: 0.6902\n",
            "Epoch 95/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0259 - accuracy: 0.9891 - val_loss: 5.2985 - val_accuracy: 0.6848\n",
            "Epoch 96/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0257 - accuracy: 0.9891 - val_loss: 5.2937 - val_accuracy: 0.6848\n",
            "Epoch 97/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 0.9891 - val_loss: 5.2743 - val_accuracy: 0.6957\n",
            "Epoch 98/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0257 - accuracy: 0.9891 - val_loss: 5.3206 - val_accuracy: 0.6848\n",
            "Epoch 99/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0257 - accuracy: 0.9891 - val_loss: 5.3095 - val_accuracy: 0.6957\n",
            "Epoch 100/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0256 - accuracy: 0.9891 - val_loss: 5.2995 - val_accuracy: 0.6902\n",
            "Epoch 101/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0259 - accuracy: 0.9891 - val_loss: 5.2629 - val_accuracy: 0.6902\n",
            "Epoch 102/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0258 - accuracy: 0.9891 - val_loss: 5.2875 - val_accuracy: 0.7011\n",
            "Epoch 103/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 0.9891 - val_loss: 5.3731 - val_accuracy: 0.6957\n",
            "Epoch 104/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9891 - val_loss: 5.3449 - val_accuracy: 0.6902\n",
            "Epoch 105/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0254 - accuracy: 0.9891 - val_loss: 5.3596 - val_accuracy: 0.6902\n",
            "Epoch 106/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9891 - val_loss: 5.4037 - val_accuracy: 0.6957\n",
            "Epoch 107/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9891 - val_loss: 5.3872 - val_accuracy: 0.6902\n",
            "Epoch 108/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0254 - accuracy: 0.9891 - val_loss: 5.3969 - val_accuracy: 0.6902\n",
            "Epoch 109/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9891 - val_loss: 5.3785 - val_accuracy: 0.6957\n",
            "Epoch 110/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9891 - val_loss: 5.3963 - val_accuracy: 0.6902\n",
            "Epoch 111/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9891 - val_loss: 5.3770 - val_accuracy: 0.6902\n",
            "Epoch 112/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 0.9891 - val_loss: 5.4069 - val_accuracy: 0.6902\n",
            "Epoch 113/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 0.9891 - val_loss: 5.4385 - val_accuracy: 0.6902\n",
            "Epoch 114/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9891 - val_loss: 5.4576 - val_accuracy: 0.6902\n",
            "Epoch 115/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9891 - val_loss: 5.3892 - val_accuracy: 0.6902\n",
            "Epoch 116/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9891 - val_loss: 5.4111 - val_accuracy: 0.6902\n",
            "Epoch 117/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9891 - val_loss: 5.4341 - val_accuracy: 0.6902\n",
            "Epoch 118/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 0.9891 - val_loss: 5.3448 - val_accuracy: 0.6902\n",
            "Epoch 119/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0262 - accuracy: 0.9891 - val_loss: 5.4019 - val_accuracy: 0.6848\n",
            "Epoch 120/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9891 - val_loss: 5.4711 - val_accuracy: 0.6848\n",
            "Epoch 121/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 0.9891 - val_loss: 5.4762 - val_accuracy: 0.6902\n",
            "Epoch 122/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0249 - accuracy: 0.9891 - val_loss: 5.5007 - val_accuracy: 0.6902\n",
            "Epoch 123/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.9891 - val_loss: 5.5284 - val_accuracy: 0.6957\n",
            "Epoch 124/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.9891 - val_loss: 5.4949 - val_accuracy: 0.6902\n",
            "Epoch 125/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9891 - val_loss: 5.4823 - val_accuracy: 0.6957\n",
            "Epoch 126/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0274 - accuracy: 0.9855 - val_loss: 5.4517 - val_accuracy: 0.6902\n",
            "Epoch 127/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 0.9891 - val_loss: 5.3920 - val_accuracy: 0.6957\n",
            "Epoch 128/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9891 - val_loss: 5.4525 - val_accuracy: 0.6957\n",
            "Epoch 129/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0251 - accuracy: 0.9891 - val_loss: 5.5002 - val_accuracy: 0.6957\n",
            "Epoch 130/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.9891 - val_loss: 5.5501 - val_accuracy: 0.6902\n",
            "Epoch 131/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 0.9891 - val_loss: 5.5485 - val_accuracy: 0.6902\n",
            "Epoch 132/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 0.9891 - val_loss: 5.5239 - val_accuracy: 0.6902\n",
            "Epoch 133/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 0.9891 - val_loss: 5.5668 - val_accuracy: 0.6902\n",
            "Epoch 134/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0246 - accuracy: 0.9891 - val_loss: 5.5989 - val_accuracy: 0.6793\n",
            "Epoch 135/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0247 - accuracy: 0.9891 - val_loss: 5.5406 - val_accuracy: 0.6957\n",
            "Epoch 136/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.9891 - val_loss: 5.5043 - val_accuracy: 0.6902\n",
            "Epoch 137/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 0.9891 - val_loss: 5.5027 - val_accuracy: 0.6902\n",
            "Epoch 138/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0247 - accuracy: 0.9891 - val_loss: 5.5184 - val_accuracy: 0.6902\n",
            "Epoch 139/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9891 - val_loss: 5.5666 - val_accuracy: 0.6848\n",
            "Epoch 140/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0244 - accuracy: 0.9891 - val_loss: 5.6566 - val_accuracy: 0.6848\n",
            "Epoch 141/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0257 - accuracy: 0.9891 - val_loss: 5.6154 - val_accuracy: 0.6902\n",
            "Epoch 142/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 0.9891 - val_loss: 5.4245 - val_accuracy: 0.6793\n",
            "Epoch 143/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 0.9891 - val_loss: 5.5960 - val_accuracy: 0.6739\n",
            "Epoch 144/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0262 - accuracy: 0.9891 - val_loss: 5.5726 - val_accuracy: 0.6739\n",
            "Epoch 145/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 0.9891 - val_loss: 5.6319 - val_accuracy: 0.6793\n",
            "Epoch 146/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0248 - accuracy: 0.9891 - val_loss: 5.5885 - val_accuracy: 0.6848\n",
            "Epoch 147/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0248 - accuracy: 0.9891 - val_loss: 5.4931 - val_accuracy: 0.6902\n",
            "Epoch 148/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0251 - accuracy: 0.9891 - val_loss: 5.5755 - val_accuracy: 0.6848\n",
            "Epoch 149/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9891 - val_loss: 5.6212 - val_accuracy: 0.6793\n",
            "Epoch 150/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 0.9891 - val_loss: 5.6602 - val_accuracy: 0.6793\n",
            "Epoch 151/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 0.9891 - val_loss: 5.6233 - val_accuracy: 0.6848\n",
            "Epoch 152/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9891 - val_loss: 5.6807 - val_accuracy: 0.6848\n",
            "Epoch 153/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9891 - val_loss: 5.5882 - val_accuracy: 0.6902\n",
            "Epoch 154/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 0.9891 - val_loss: 5.6556 - val_accuracy: 0.6848\n",
            "Epoch 155/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 0.9891 - val_loss: 5.7009 - val_accuracy: 0.6848\n",
            "Epoch 156/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 0.9891 - val_loss: 5.6998 - val_accuracy: 0.6848\n",
            "Epoch 157/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0237 - accuracy: 0.9891 - val_loss: 5.7426 - val_accuracy: 0.6848\n",
            "Epoch 158/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.9891 - val_loss: 5.6466 - val_accuracy: 0.6848\n",
            "Epoch 159/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 0.9891 - val_loss: 5.7316 - val_accuracy: 0.6793\n",
            "Epoch 160/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 0.9891 - val_loss: 5.7787 - val_accuracy: 0.6848\n",
            "Epoch 161/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0239 - accuracy: 0.9891 - val_loss: 5.7327 - val_accuracy: 0.6848\n",
            "Epoch 162/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0237 - accuracy: 0.9891 - val_loss: 5.7409 - val_accuracy: 0.6848\n",
            "Epoch 163/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0237 - accuracy: 0.9891 - val_loss: 5.7408 - val_accuracy: 0.6848\n",
            "Epoch 164/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0236 - accuracy: 0.9891 - val_loss: 5.7621 - val_accuracy: 0.6848\n",
            "Epoch 165/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 0.9891 - val_loss: 5.7776 - val_accuracy: 0.6793\n",
            "Epoch 166/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0240 - accuracy: 0.9891 - val_loss: 5.6972 - val_accuracy: 0.6848\n",
            "Epoch 167/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0237 - accuracy: 0.9891 - val_loss: 5.6494 - val_accuracy: 0.6902\n",
            "Epoch 168/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 0.9891 - val_loss: 5.7377 - val_accuracy: 0.6902\n",
            "Epoch 169/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0232 - accuracy: 0.9891 - val_loss: 5.8132 - val_accuracy: 0.6793\n",
            "Epoch 170/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0234 - accuracy: 0.9891 - val_loss: 5.7667 - val_accuracy: 0.6848\n",
            "Epoch 171/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0239 - accuracy: 0.9891 - val_loss: 5.8400 - val_accuracy: 0.6793\n",
            "Epoch 172/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0237 - accuracy: 0.9891 - val_loss: 5.7590 - val_accuracy: 0.6848\n",
            "Epoch 173/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0238 - accuracy: 0.9891 - val_loss: 5.7948 - val_accuracy: 0.6793\n",
            "Epoch 174/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 0.9891 - val_loss: 5.8421 - val_accuracy: 0.6793\n",
            "Epoch 175/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.9891 - val_loss: 5.8518 - val_accuracy: 0.6793\n",
            "Epoch 176/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0230 - accuracy: 0.9891 - val_loss: 5.8101 - val_accuracy: 0.6848\n",
            "Epoch 177/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0231 - accuracy: 0.9891 - val_loss: 5.8585 - val_accuracy: 0.6793\n",
            "Epoch 178/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0228 - accuracy: 0.9891 - val_loss: 5.8729 - val_accuracy: 0.6793\n",
            "Epoch 179/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0228 - accuracy: 0.9891 - val_loss: 5.8253 - val_accuracy: 0.6848\n",
            "Epoch 180/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0229 - accuracy: 0.9891 - val_loss: 5.8845 - val_accuracy: 0.6793\n",
            "Epoch 181/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0229 - accuracy: 0.9891 - val_loss: 5.7950 - val_accuracy: 0.6957\n",
            "Epoch 182/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 0.9891 - val_loss: 5.7571 - val_accuracy: 0.6957\n",
            "Epoch 183/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0227 - accuracy: 0.9891 - val_loss: 5.8745 - val_accuracy: 0.6848\n",
            "Epoch 184/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.9891 - val_loss: 5.8630 - val_accuracy: 0.6902\n",
            "Epoch 185/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0230 - accuracy: 0.9891 - val_loss: 5.8468 - val_accuracy: 0.6902\n",
            "Epoch 186/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0225 - accuracy: 0.9891 - val_loss: 5.9457 - val_accuracy: 0.6902\n",
            "Epoch 187/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0226 - accuracy: 0.9891 - val_loss: 5.9690 - val_accuracy: 0.6793\n",
            "Epoch 188/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0227 - accuracy: 0.9891 - val_loss: 5.9303 - val_accuracy: 0.6848\n",
            "Epoch 189/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0226 - accuracy: 0.9891 - val_loss: 5.9923 - val_accuracy: 0.6793\n",
            "Epoch 190/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0225 - accuracy: 0.9891 - val_loss: 6.0013 - val_accuracy: 0.6793\n",
            "Epoch 191/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0225 - accuracy: 0.9891 - val_loss: 5.9615 - val_accuracy: 0.6848\n",
            "Epoch 192/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0223 - accuracy: 0.9891 - val_loss: 5.9885 - val_accuracy: 0.6902\n",
            "Epoch 193/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0221 - accuracy: 0.9891 - val_loss: 5.9930 - val_accuracy: 0.6902\n",
            "Epoch 194/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0224 - accuracy: 0.9891 - val_loss: 6.0057 - val_accuracy: 0.6902\n",
            "Epoch 195/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0223 - accuracy: 0.9891 - val_loss: 6.0186 - val_accuracy: 0.6793\n",
            "Epoch 196/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0224 - accuracy: 0.9891 - val_loss: 5.8980 - val_accuracy: 0.6902\n",
            "Epoch 197/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0225 - accuracy: 0.9891 - val_loss: 5.9940 - val_accuracy: 0.6848\n",
            "Epoch 198/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0220 - accuracy: 0.9891 - val_loss: 5.9764 - val_accuracy: 0.6902\n",
            "Epoch 199/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0221 - accuracy: 0.9891 - val_loss: 6.0014 - val_accuracy: 0.6957\n",
            "Epoch 200/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0220 - accuracy: 0.9891 - val_loss: 6.0060 - val_accuracy: 0.6848\n",
            "Epoch 201/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0221 - accuracy: 0.9891 - val_loss: 6.0171 - val_accuracy: 0.6793\n",
            "Epoch 202/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0225 - accuracy: 0.9891 - val_loss: 6.0621 - val_accuracy: 0.6739\n",
            "Epoch 203/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0238 - accuracy: 0.9891 - val_loss: 5.9980 - val_accuracy: 0.6848\n",
            "Epoch 204/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0226 - accuracy: 0.9891 - val_loss: 5.9866 - val_accuracy: 0.6902\n",
            "Epoch 205/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0222 - accuracy: 0.9891 - val_loss: 6.0412 - val_accuracy: 0.6902\n",
            "Epoch 206/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 0.9891 - val_loss: 6.0972 - val_accuracy: 0.6848\n",
            "Epoch 207/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0222 - accuracy: 0.9891 - val_loss: 6.0456 - val_accuracy: 0.6848\n",
            "Epoch 208/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0219 - accuracy: 0.9891 - val_loss: 6.0544 - val_accuracy: 0.7011\n",
            "Epoch 209/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0219 - accuracy: 0.9891 - val_loss: 6.0890 - val_accuracy: 0.6902\n",
            "Epoch 210/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 0.9891 - val_loss: 6.0686 - val_accuracy: 0.6848\n",
            "Epoch 211/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0221 - accuracy: 0.9891 - val_loss: 6.1089 - val_accuracy: 0.6957\n",
            "Epoch 212/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 0.9891 - val_loss: 6.1804 - val_accuracy: 0.6848\n",
            "Epoch 213/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 0.9891 - val_loss: 6.1720 - val_accuracy: 0.6793\n",
            "Epoch 214/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9891 - val_loss: 6.1608 - val_accuracy: 0.6957\n",
            "Epoch 215/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0220 - accuracy: 0.9891 - val_loss: 6.1498 - val_accuracy: 0.6957\n",
            "Epoch 216/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0214 - accuracy: 0.9891 - val_loss: 6.2167 - val_accuracy: 0.6902\n",
            "Epoch 217/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0214 - accuracy: 0.9891 - val_loss: 6.1923 - val_accuracy: 0.6957\n",
            "Epoch 218/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0214 - accuracy: 0.9891 - val_loss: 6.1876 - val_accuracy: 0.6902\n",
            "Epoch 219/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0223 - accuracy: 0.9891 - val_loss: 5.9776 - val_accuracy: 0.6957\n",
            "Epoch 220/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.9891 - val_loss: 6.2142 - val_accuracy: 0.6957\n",
            "Epoch 221/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 0.9891 - val_loss: 6.1043 - val_accuracy: 0.6902\n",
            "Epoch 222/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.9891 - val_loss: 6.0821 - val_accuracy: 0.6793\n",
            "Epoch 223/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0239 - accuracy: 0.9855 - val_loss: 6.2588 - val_accuracy: 0.6793\n",
            "Epoch 224/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.9819 - val_loss: 6.1863 - val_accuracy: 0.6739\n",
            "Epoch 225/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0237 - accuracy: 0.9891 - val_loss: 6.0169 - val_accuracy: 0.6793\n",
            "Epoch 226/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 0.9891 - val_loss: 5.9125 - val_accuracy: 0.6902\n",
            "Epoch 227/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0222 - accuracy: 0.9891 - val_loss: 6.0403 - val_accuracy: 0.6902\n",
            "Epoch 228/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 0.9891 - val_loss: 6.0430 - val_accuracy: 0.6902\n",
            "Epoch 229/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0217 - accuracy: 0.9891 - val_loss: 6.1057 - val_accuracy: 0.6902\n",
            "Epoch 230/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0217 - accuracy: 0.9891 - val_loss: 6.1246 - val_accuracy: 0.6902\n",
            "Epoch 231/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9891 - val_loss: 6.1572 - val_accuracy: 0.6902\n",
            "Epoch 232/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0214 - accuracy: 0.9891 - val_loss: 6.1834 - val_accuracy: 0.6848\n",
            "Epoch 233/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9891 - val_loss: 6.1613 - val_accuracy: 0.6957\n",
            "Epoch 234/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0213 - accuracy: 0.9891 - val_loss: 6.2204 - val_accuracy: 0.6848\n",
            "Epoch 235/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0213 - accuracy: 0.9891 - val_loss: 6.2483 - val_accuracy: 0.6848\n",
            "Epoch 236/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0211 - accuracy: 0.9891 - val_loss: 6.2554 - val_accuracy: 0.6848\n",
            "Epoch 237/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.9891 - val_loss: 6.2731 - val_accuracy: 0.6902\n",
            "Epoch 238/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0212 - accuracy: 0.9891 - val_loss: 6.2481 - val_accuracy: 0.6902\n",
            "Epoch 239/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.9891 - val_loss: 6.2378 - val_accuracy: 0.6848\n",
            "Epoch 240/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0211 - accuracy: 0.9891 - val_loss: 6.2151 - val_accuracy: 0.6848\n",
            "Epoch 241/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0210 - accuracy: 0.9891 - val_loss: 6.2493 - val_accuracy: 0.6902\n",
            "Epoch 242/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0207 - accuracy: 0.9891 - val_loss: 6.2693 - val_accuracy: 0.6902\n",
            "Epoch 243/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0208 - accuracy: 0.9891 - val_loss: 6.2709 - val_accuracy: 0.6848\n",
            "Epoch 244/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 0.9891 - val_loss: 6.2942 - val_accuracy: 0.6793\n",
            "Epoch 245/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0205 - accuracy: 0.9891 - val_loss: 6.3033 - val_accuracy: 0.6848\n",
            "Epoch 246/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0207 - accuracy: 0.9891 - val_loss: 6.2965 - val_accuracy: 0.6848\n",
            "Epoch 247/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0205 - accuracy: 0.9891 - val_loss: 6.3187 - val_accuracy: 0.6848\n",
            "Epoch 248/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0204 - accuracy: 0.9891 - val_loss: 6.3431 - val_accuracy: 0.6793\n",
            "Epoch 249/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0208 - accuracy: 0.9928 - val_loss: 6.3240 - val_accuracy: 0.6793\n",
            "Epoch 250/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0205 - accuracy: 0.9928 - val_loss: 6.3375 - val_accuracy: 0.6739\n",
            "Epoch 251/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0206 - accuracy: 0.9928 - val_loss: 6.3430 - val_accuracy: 0.6793\n",
            "Epoch 252/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 0.9928 - val_loss: 6.3576 - val_accuracy: 0.6739\n",
            "Epoch 253/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0206 - accuracy: 0.9928 - val_loss: 6.2628 - val_accuracy: 0.6793\n",
            "Epoch 254/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 0.9891 - val_loss: 6.3106 - val_accuracy: 0.6793\n",
            "Epoch 255/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0203 - accuracy: 0.9928 - val_loss: 6.3435 - val_accuracy: 0.6793\n",
            "Epoch 256/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0202 - accuracy: 0.9928 - val_loss: 6.3564 - val_accuracy: 0.6793\n",
            "Epoch 257/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0201 - accuracy: 0.9928 - val_loss: 6.3412 - val_accuracy: 0.6793\n",
            "Epoch 258/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0201 - accuracy: 0.9928 - val_loss: 6.3696 - val_accuracy: 0.6793\n",
            "Epoch 259/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 0.9891 - val_loss: 6.3560 - val_accuracy: 0.6793\n",
            "Epoch 260/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0200 - accuracy: 0.9928 - val_loss: 6.3785 - val_accuracy: 0.6793\n",
            "Epoch 261/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9928 - val_loss: 6.3833 - val_accuracy: 0.6793\n",
            "Epoch 262/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0205 - accuracy: 0.9891 - val_loss: 6.3601 - val_accuracy: 0.6793\n",
            "Epoch 263/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0199 - accuracy: 0.9928 - val_loss: 6.4088 - val_accuracy: 0.6793\n",
            "Epoch 264/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 0.9928 - val_loss: 6.4625 - val_accuracy: 0.6739\n",
            "Epoch 265/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9928 - val_loss: 6.4328 - val_accuracy: 0.6739\n",
            "Epoch 266/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9928 - val_loss: 6.4307 - val_accuracy: 0.6793\n",
            "Epoch 267/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0272 - accuracy: 0.9891 - val_loss: 6.3792 - val_accuracy: 0.6576\n",
            "Epoch 268/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0319 - accuracy: 0.9891 - val_loss: 6.4233 - val_accuracy: 0.6902\n",
            "Epoch 269/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.9710 - val_loss: 5.8175 - val_accuracy: 0.6685\n",
            "Epoch 270/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0468 - accuracy: 0.9855 - val_loss: 6.0709 - val_accuracy: 0.6848\n",
            "Epoch 271/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9891 - val_loss: 6.0303 - val_accuracy: 0.6685\n",
            "Epoch 272/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0221 - accuracy: 0.9891 - val_loss: 6.1217 - val_accuracy: 0.6793\n",
            "Epoch 273/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0211 - accuracy: 0.9891 - val_loss: 6.1648 - val_accuracy: 0.6848\n",
            "Epoch 274/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 0.9891 - val_loss: 6.1289 - val_accuracy: 0.6902\n",
            "Epoch 275/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.9891 - val_loss: 6.1400 - val_accuracy: 0.6848\n",
            "Epoch 276/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0203 - accuracy: 0.9891 - val_loss: 6.1833 - val_accuracy: 0.6902\n",
            "Epoch 277/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0202 - accuracy: 0.9891 - val_loss: 6.1924 - val_accuracy: 0.6902\n",
            "Epoch 278/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0201 - accuracy: 0.9891 - val_loss: 6.2004 - val_accuracy: 0.6902\n",
            "Epoch 279/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9891 - val_loss: 6.2265 - val_accuracy: 0.6902\n",
            "Epoch 280/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0200 - accuracy: 0.9891 - val_loss: 6.2228 - val_accuracy: 0.6848\n",
            "Epoch 281/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 0.9891 - val_loss: 6.2252 - val_accuracy: 0.6848\n",
            "Epoch 282/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0200 - accuracy: 0.9891 - val_loss: 6.2219 - val_accuracy: 0.6848\n",
            "Epoch 283/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0199 - accuracy: 0.9891 - val_loss: 6.2329 - val_accuracy: 0.6848\n",
            "Epoch 284/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0198 - accuracy: 0.9891 - val_loss: 6.2614 - val_accuracy: 0.6848\n",
            "Epoch 285/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 0.9928 - val_loss: 6.2761 - val_accuracy: 0.6848\n",
            "Epoch 286/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0197 - accuracy: 0.9928 - val_loss: 6.2603 - val_accuracy: 0.6848\n",
            "Epoch 287/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0198 - accuracy: 0.9891 - val_loss: 6.2712 - val_accuracy: 0.6848\n",
            "Epoch 288/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 0.9928 - val_loss: 6.2959 - val_accuracy: 0.6848\n",
            "Epoch 289/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9928 - val_loss: 6.3024 - val_accuracy: 0.6848\n",
            "Epoch 290/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0196 - accuracy: 0.9928 - val_loss: 6.2947 - val_accuracy: 0.6848\n",
            "Epoch 291/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9928 - val_loss: 6.2831 - val_accuracy: 0.6902\n",
            "Epoch 292/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.9928 - val_loss: 6.3074 - val_accuracy: 0.6848\n",
            "Epoch 293/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0195 - accuracy: 0.9928 - val_loss: 6.3335 - val_accuracy: 0.6848\n",
            "Epoch 294/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0195 - accuracy: 0.9928 - val_loss: 6.3400 - val_accuracy: 0.6848\n",
            "Epoch 295/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0195 - accuracy: 0.9928 - val_loss: 6.3122 - val_accuracy: 0.6902\n",
            "Epoch 296/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.9928 - val_loss: 6.3581 - val_accuracy: 0.6848\n",
            "Epoch 297/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.9928 - val_loss: 6.3535 - val_accuracy: 0.6902\n",
            "Epoch 298/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9928 - val_loss: 6.3557 - val_accuracy: 0.6902\n",
            "Epoch 299/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 0.9928 - val_loss: 6.3678 - val_accuracy: 0.6848\n",
            "Epoch 300/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 0.9928 - val_loss: 6.3703 - val_accuracy: 0.6848\n",
            "Epoch 301/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.9928 - val_loss: 6.3847 - val_accuracy: 0.6848\n",
            "Epoch 302/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0192 - accuracy: 0.9928 - val_loss: 6.3686 - val_accuracy: 0.6848\n",
            "Epoch 303/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0193 - accuracy: 0.9928 - val_loss: 6.3692 - val_accuracy: 0.6848\n",
            "Epoch 304/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0192 - accuracy: 0.9928 - val_loss: 6.4069 - val_accuracy: 0.6793\n",
            "Epoch 305/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9928 - val_loss: 6.4148 - val_accuracy: 0.6793\n",
            "Epoch 306/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0193 - accuracy: 0.9928 - val_loss: 6.4215 - val_accuracy: 0.6793\n",
            "Epoch 307/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0191 - accuracy: 0.9928 - val_loss: 6.4202 - val_accuracy: 0.6793\n",
            "Epoch 308/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0190 - accuracy: 0.9928 - val_loss: 6.4276 - val_accuracy: 0.6793\n",
            "Epoch 309/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 0.9928 - val_loss: 6.4358 - val_accuracy: 0.6793\n",
            "Epoch 310/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 0.9928 - val_loss: 6.4336 - val_accuracy: 0.6793\n",
            "Epoch 311/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 0.9928 - val_loss: 6.4537 - val_accuracy: 0.6793\n",
            "Epoch 312/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0190 - accuracy: 0.9928 - val_loss: 6.4385 - val_accuracy: 0.6793\n",
            "Epoch 313/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 0.9928 - val_loss: 6.4134 - val_accuracy: 0.6848\n",
            "Epoch 314/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 0.9928 - val_loss: 6.4533 - val_accuracy: 0.6793\n",
            "Epoch 315/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9928 - val_loss: 6.4579 - val_accuracy: 0.6793\n",
            "Epoch 316/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0188 - accuracy: 0.9928 - val_loss: 6.4561 - val_accuracy: 0.6793\n",
            "Epoch 317/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.9928 - val_loss: 6.4556 - val_accuracy: 0.6793\n",
            "Epoch 318/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0188 - accuracy: 0.9928 - val_loss: 6.4589 - val_accuracy: 0.6793\n",
            "Epoch 319/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0188 - accuracy: 0.9928 - val_loss: 6.4540 - val_accuracy: 0.6793\n",
            "Epoch 320/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 0.9928 - val_loss: 6.4657 - val_accuracy: 0.6793\n",
            "Epoch 321/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0187 - accuracy: 0.9928 - val_loss: 6.4850 - val_accuracy: 0.6793\n",
            "Epoch 322/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9928 - val_loss: 6.4884 - val_accuracy: 0.6793\n",
            "Epoch 323/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0187 - accuracy: 0.9928 - val_loss: 6.4860 - val_accuracy: 0.6793\n",
            "Epoch 324/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9928 - val_loss: 6.4877 - val_accuracy: 0.6793\n",
            "Epoch 325/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0187 - accuracy: 0.9928 - val_loss: 6.4890 - val_accuracy: 0.6793\n",
            "Epoch 326/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9928 - val_loss: 6.4995 - val_accuracy: 0.6793\n",
            "Epoch 327/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0186 - accuracy: 0.9928 - val_loss: 6.5108 - val_accuracy: 0.6739\n",
            "Epoch 328/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0186 - accuracy: 0.9928 - val_loss: 6.5161 - val_accuracy: 0.6793\n",
            "Epoch 329/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.9928 - val_loss: 6.5203 - val_accuracy: 0.6793\n",
            "Epoch 330/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0185 - accuracy: 0.9928 - val_loss: 6.5300 - val_accuracy: 0.6739\n",
            "Epoch 331/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.9928 - val_loss: 6.5216 - val_accuracy: 0.6739\n",
            "Epoch 332/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.9928 - val_loss: 6.5400 - val_accuracy: 0.6793\n",
            "Epoch 333/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.9928 - val_loss: 6.5496 - val_accuracy: 0.6793\n",
            "Epoch 334/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 0.9928 - val_loss: 6.5077 - val_accuracy: 0.6793\n",
            "Epoch 335/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0181 - accuracy: 0.9928 - val_loss: 6.5775 - val_accuracy: 0.6685\n",
            "Epoch 336/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0190 - accuracy: 0.9928 - val_loss: 6.6134 - val_accuracy: 0.6685\n",
            "Epoch 337/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.9928 - val_loss: 6.5751 - val_accuracy: 0.6739\n",
            "Epoch 338/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.9928 - val_loss: 6.5758 - val_accuracy: 0.6739\n",
            "Epoch 339/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.9928 - val_loss: 6.5710 - val_accuracy: 0.6793\n",
            "Epoch 340/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.9928 - val_loss: 6.5832 - val_accuracy: 0.6739\n",
            "Epoch 341/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.9928 - val_loss: 6.5574 - val_accuracy: 0.6739\n",
            "Epoch 342/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 0.9928 - val_loss: 6.6420 - val_accuracy: 0.6793\n",
            "Epoch 343/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0183 - accuracy: 0.9928 - val_loss: 6.6132 - val_accuracy: 0.6739\n",
            "Epoch 344/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0181 - accuracy: 0.9928 - val_loss: 6.6218 - val_accuracy: 0.6793\n",
            "Epoch 345/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9928 - val_loss: 6.6208 - val_accuracy: 0.6739\n",
            "Epoch 346/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9928 - val_loss: 6.6074 - val_accuracy: 0.6739\n",
            "Epoch 347/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 0.9928 - val_loss: 6.6155 - val_accuracy: 0.6685\n",
            "Epoch 348/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9928 - val_loss: 6.6249 - val_accuracy: 0.6739\n",
            "Epoch 349/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0180 - accuracy: 0.9928 - val_loss: 6.6163 - val_accuracy: 0.6685\n",
            "Epoch 350/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0180 - accuracy: 0.9928 - val_loss: 6.6449 - val_accuracy: 0.6739\n",
            "Epoch 351/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9928 - val_loss: 6.6453 - val_accuracy: 0.6793\n",
            "Epoch 352/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0179 - accuracy: 0.9928 - val_loss: 6.6539 - val_accuracy: 0.6739\n",
            "Epoch 353/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0179 - accuracy: 0.9928 - val_loss: 6.6624 - val_accuracy: 0.6739\n",
            "Epoch 354/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9928 - val_loss: 6.6438 - val_accuracy: 0.6739\n",
            "Epoch 355/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9928 - val_loss: 6.6655 - val_accuracy: 0.6739\n",
            "Epoch 356/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0181 - accuracy: 0.9928 - val_loss: 6.6768 - val_accuracy: 0.6793\n",
            "Epoch 357/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9928 - val_loss: 6.6151 - val_accuracy: 0.6848\n",
            "Epoch 358/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 0.9928 - val_loss: 6.6553 - val_accuracy: 0.6848\n",
            "Epoch 359/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9928 - val_loss: 6.6300 - val_accuracy: 0.6739\n",
            "Epoch 360/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0175 - accuracy: 0.9928 - val_loss: 6.6438 - val_accuracy: 0.6739\n",
            "Epoch 361/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0175 - accuracy: 0.9928 - val_loss: 6.6548 - val_accuracy: 0.6793\n",
            "Epoch 362/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0173 - accuracy: 0.9928 - val_loss: 6.6647 - val_accuracy: 0.6848\n",
            "Epoch 363/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 0.9928 - val_loss: 6.6598 - val_accuracy: 0.6848\n",
            "Epoch 364/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0173 - accuracy: 0.9928 - val_loss: 6.6879 - val_accuracy: 0.6793\n",
            "Epoch 365/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0172 - accuracy: 0.9928 - val_loss: 6.6766 - val_accuracy: 0.6848\n",
            "Epoch 366/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0172 - accuracy: 0.9928 - val_loss: 6.6679 - val_accuracy: 0.6793\n",
            "Epoch 367/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0171 - accuracy: 0.9928 - val_loss: 6.7142 - val_accuracy: 0.6793\n",
            "Epoch 368/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0177 - accuracy: 0.9928 - val_loss: 6.6474 - val_accuracy: 0.6793\n",
            "Epoch 369/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0175 - accuracy: 0.9928 - val_loss: 6.7303 - val_accuracy: 0.6793\n",
            "Epoch 370/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0170 - accuracy: 0.9928 - val_loss: 6.7147 - val_accuracy: 0.6739\n",
            "Epoch 371/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.9928 - val_loss: 6.6747 - val_accuracy: 0.6793\n",
            "Epoch 372/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9928 - val_loss: 6.7620 - val_accuracy: 0.6739\n",
            "Epoch 373/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0169 - accuracy: 0.9928 - val_loss: 6.7034 - val_accuracy: 0.6739\n",
            "Epoch 374/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9928 - val_loss: 6.7358 - val_accuracy: 0.6848\n",
            "Epoch 375/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0169 - accuracy: 0.9928 - val_loss: 6.7347 - val_accuracy: 0.6793\n",
            "Epoch 376/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9928 - val_loss: 6.7953 - val_accuracy: 0.6793\n",
            "Epoch 377/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9928 - val_loss: 6.7564 - val_accuracy: 0.6793\n",
            "Epoch 378/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0170 - accuracy: 0.9928 - val_loss: 6.8253 - val_accuracy: 0.6739\n",
            "Epoch 379/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9928 - val_loss: 6.7555 - val_accuracy: 0.6793\n",
            "Epoch 380/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9928 - val_loss: 6.7778 - val_accuracy: 0.6739\n",
            "Epoch 381/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9928 - val_loss: 6.8000 - val_accuracy: 0.6793\n",
            "Epoch 382/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 0.9928 - val_loss: 6.7782 - val_accuracy: 0.6848\n",
            "Epoch 383/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0170 - accuracy: 0.9928 - val_loss: 6.8286 - val_accuracy: 0.6793\n",
            "Epoch 384/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9928 - val_loss: 6.7362 - val_accuracy: 0.6739\n",
            "Epoch 385/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9928 - val_loss: 6.7925 - val_accuracy: 0.6739\n",
            "Epoch 386/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0169 - accuracy: 0.9928 - val_loss: 6.7745 - val_accuracy: 0.6739\n",
            "Epoch 387/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 0.9928 - val_loss: 6.8687 - val_accuracy: 0.6793\n",
            "Epoch 388/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0167 - accuracy: 0.9928 - val_loss: 6.8147 - val_accuracy: 0.6739\n",
            "Epoch 389/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 0.9928 - val_loss: 6.8343 - val_accuracy: 0.6793\n",
            "Epoch 390/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 0.9928 - val_loss: 6.8373 - val_accuracy: 0.6739\n",
            "Epoch 391/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.9928 - val_loss: 6.8316 - val_accuracy: 0.6739\n",
            "Epoch 392/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 0.9928 - val_loss: 6.8527 - val_accuracy: 0.6739\n",
            "Epoch 393/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 0.9928 - val_loss: 6.8955 - val_accuracy: 0.6793\n",
            "Epoch 394/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.9928 - val_loss: 6.8758 - val_accuracy: 0.6793\n",
            "Epoch 395/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.9928 - val_loss: 6.8969 - val_accuracy: 0.6793\n",
            "Epoch 396/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.9928 - val_loss: 6.8714 - val_accuracy: 0.6739\n",
            "Epoch 397/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 0.9928 - val_loss: 6.9278 - val_accuracy: 0.6793\n",
            "Epoch 398/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9928 - val_loss: 6.9027 - val_accuracy: 0.6739\n",
            "Epoch 399/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 0.9928 - val_loss: 6.8873 - val_accuracy: 0.6739\n",
            "Epoch 400/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 0.9928 - val_loss: 6.9360 - val_accuracy: 0.6739\n",
            "Epoch 401/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9928 - val_loss: 6.9830 - val_accuracy: 0.6793\n",
            "Epoch 402/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9928 - val_loss: 6.9371 - val_accuracy: 0.6739\n",
            "Epoch 403/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 0.9928 - val_loss: 6.9670 - val_accuracy: 0.6739\n",
            "Epoch 404/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0162 - accuracy: 0.9928 - val_loss: 6.9350 - val_accuracy: 0.6739\n",
            "Epoch 405/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0162 - accuracy: 0.9928 - val_loss: 6.9556 - val_accuracy: 0.6739\n",
            "Epoch 406/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0162 - accuracy: 0.9928 - val_loss: 6.9889 - val_accuracy: 0.6739\n",
            "Epoch 407/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0167 - accuracy: 0.9928 - val_loss: 6.9609 - val_accuracy: 0.6793\n",
            "Epoch 408/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 0.9928 - val_loss: 7.0730 - val_accuracy: 0.6793\n",
            "Epoch 409/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.9928 - val_loss: 7.0047 - val_accuracy: 0.6793\n",
            "Epoch 410/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0160 - accuracy: 0.9928 - val_loss: 7.0315 - val_accuracy: 0.6793\n",
            "Epoch 411/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9928 - val_loss: 7.0283 - val_accuracy: 0.6793\n",
            "Epoch 412/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.9928 - val_loss: 7.0104 - val_accuracy: 0.6793\n",
            "Epoch 413/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9928 - val_loss: 7.0365 - val_accuracy: 0.6793\n",
            "Epoch 414/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9928 - val_loss: 7.0192 - val_accuracy: 0.6793\n",
            "Epoch 415/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0159 - accuracy: 0.9928 - val_loss: 7.0290 - val_accuracy: 0.6739\n",
            "Epoch 416/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0160 - accuracy: 0.9928 - val_loss: 7.0456 - val_accuracy: 0.6739\n",
            "Epoch 417/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9928 - val_loss: 7.0300 - val_accuracy: 0.6793\n",
            "Epoch 418/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0158 - accuracy: 0.9928 - val_loss: 7.0609 - val_accuracy: 0.6739\n",
            "Epoch 419/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 0.9928 - val_loss: 7.0679 - val_accuracy: 0.6739\n",
            "Epoch 420/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 0.9928 - val_loss: 7.0677 - val_accuracy: 0.6793\n",
            "Epoch 421/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9928 - val_loss: 7.0908 - val_accuracy: 0.6793\n",
            "Epoch 422/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0158 - accuracy: 0.9928 - val_loss: 7.0697 - val_accuracy: 0.6739\n",
            "Epoch 423/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9928 - val_loss: 7.1186 - val_accuracy: 0.6793\n",
            "Epoch 424/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9928 - val_loss: 7.0906 - val_accuracy: 0.6739\n",
            "Epoch 425/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 0.9928 - val_loss: 7.1228 - val_accuracy: 0.6739\n",
            "Epoch 426/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9928 - val_loss: 7.0950 - val_accuracy: 0.6739\n",
            "Epoch 427/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 0.9928 - val_loss: 7.1108 - val_accuracy: 0.6793\n",
            "Epoch 428/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.9928 - val_loss: 7.1492 - val_accuracy: 0.6793\n",
            "Epoch 429/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0157 - accuracy: 0.9928 - val_loss: 7.1333 - val_accuracy: 0.6739\n",
            "Epoch 430/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.9928 - val_loss: 7.1260 - val_accuracy: 0.6739\n",
            "Epoch 431/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0154 - accuracy: 0.9928 - val_loss: 7.1188 - val_accuracy: 0.6739\n",
            "Epoch 432/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9928 - val_loss: 7.2041 - val_accuracy: 0.6793\n",
            "Epoch 433/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9928 - val_loss: 7.1698 - val_accuracy: 0.6739\n",
            "Epoch 434/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 0.9928 - val_loss: 7.1903 - val_accuracy: 0.6739\n",
            "Epoch 435/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0154 - accuracy: 0.9928 - val_loss: 7.2077 - val_accuracy: 0.6793\n",
            "Epoch 436/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9928 - val_loss: 7.2214 - val_accuracy: 0.6793\n",
            "Epoch 437/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9928 - val_loss: 7.1449 - val_accuracy: 0.6739\n",
            "Epoch 438/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9928 - val_loss: 7.2197 - val_accuracy: 0.6739\n",
            "Epoch 439/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 0.9928 - val_loss: 7.1961 - val_accuracy: 0.6739\n",
            "Epoch 440/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 0.9928 - val_loss: 7.2257 - val_accuracy: 0.6739\n",
            "Epoch 441/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 0.9928 - val_loss: 7.2032 - val_accuracy: 0.6739\n",
            "Epoch 442/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0151 - accuracy: 0.9928 - val_loss: 7.1881 - val_accuracy: 0.6739\n",
            "Epoch 443/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0153 - accuracy: 0.9928 - val_loss: 7.2275 - val_accuracy: 0.6739\n",
            "Epoch 444/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9928 - val_loss: 7.2589 - val_accuracy: 0.6793\n",
            "Epoch 445/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 0.9928 - val_loss: 7.2098 - val_accuracy: 0.6739\n",
            "Epoch 446/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 0.9928 - val_loss: 7.2423 - val_accuracy: 0.6739\n",
            "Epoch 447/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 0.9928 - val_loss: 7.2788 - val_accuracy: 0.6739\n",
            "Epoch 448/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0160 - accuracy: 0.9928 - val_loss: 7.2622 - val_accuracy: 0.6957\n",
            "Epoch 449/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 0.9928 - val_loss: 7.2533 - val_accuracy: 0.6793\n",
            "Epoch 450/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9928 - val_loss: 7.2395 - val_accuracy: 0.6793\n",
            "Epoch 451/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0151 - accuracy: 0.9928 - val_loss: 7.2826 - val_accuracy: 0.6685\n",
            "Epoch 452/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0153 - accuracy: 0.9928 - val_loss: 7.2916 - val_accuracy: 0.6685\n",
            "Epoch 453/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 0.9928 - val_loss: 7.3251 - val_accuracy: 0.6793\n",
            "Epoch 454/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0153 - accuracy: 0.9928 - val_loss: 7.3012 - val_accuracy: 0.6793\n",
            "Epoch 455/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 0.9928 - val_loss: 7.3148 - val_accuracy: 0.6739\n",
            "Epoch 456/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0153 - accuracy: 0.9928 - val_loss: 7.3181 - val_accuracy: 0.6739\n",
            "Epoch 457/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9928 - val_loss: 7.3465 - val_accuracy: 0.6793\n",
            "Epoch 458/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0150 - accuracy: 0.9928 - val_loss: 7.3060 - val_accuracy: 0.6739\n",
            "Epoch 459/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 0.9928 - val_loss: 7.2661 - val_accuracy: 0.6793\n",
            "Epoch 460/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0151 - accuracy: 0.9928 - val_loss: 7.3142 - val_accuracy: 0.6685\n",
            "Epoch 461/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9928 - val_loss: 7.3629 - val_accuracy: 0.6685\n",
            "Epoch 462/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0148 - accuracy: 0.9928 - val_loss: 7.4023 - val_accuracy: 0.6793\n",
            "Epoch 463/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0152 - accuracy: 0.9928 - val_loss: 7.3890 - val_accuracy: 0.6685\n",
            "Epoch 464/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9928 - val_loss: 7.4015 - val_accuracy: 0.6793\n",
            "Epoch 465/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0152 - accuracy: 0.9928 - val_loss: 7.3524 - val_accuracy: 0.6793\n",
            "Epoch 466/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0150 - accuracy: 0.9928 - val_loss: 7.4080 - val_accuracy: 0.6793\n",
            "Epoch 467/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0150 - accuracy: 0.9928 - val_loss: 7.4209 - val_accuracy: 0.6848\n",
            "Epoch 468/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0184 - accuracy: 0.9891 - val_loss: 7.1693 - val_accuracy: 0.6739\n",
            "Epoch 469/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0169 - accuracy: 0.9964 - val_loss: 8.0698 - val_accuracy: 0.6739\n",
            "Epoch 470/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0821 - accuracy: 0.9710 - val_loss: 6.9404 - val_accuracy: 0.6902\n",
            "Epoch 471/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.1212 - accuracy: 0.9601 - val_loss: 7.1265 - val_accuracy: 0.6957\n",
            "Epoch 472/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0744 - accuracy: 0.9674 - val_loss: 6.7081 - val_accuracy: 0.6848\n",
            "Epoch 473/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0680 - accuracy: 0.9819 - val_loss: 6.7343 - val_accuracy: 0.6957\n",
            "Epoch 474/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 0.9928 - val_loss: 6.7981 - val_accuracy: 0.6957\n",
            "Epoch 475/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9928 - val_loss: 6.7500 - val_accuracy: 0.6848\n",
            "Epoch 476/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 0.9928 - val_loss: 6.7419 - val_accuracy: 0.6848\n",
            "Epoch 477/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9928 - val_loss: 6.7526 - val_accuracy: 0.6848\n",
            "Epoch 478/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9928 - val_loss: 6.7533 - val_accuracy: 0.6848\n",
            "Epoch 479/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9928 - val_loss: 6.7596 - val_accuracy: 0.6848\n",
            "Epoch 480/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.9928 - val_loss: 6.7695 - val_accuracy: 0.6848\n",
            "Epoch 481/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9928 - val_loss: 6.7783 - val_accuracy: 0.6848\n",
            "Epoch 482/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 0.9928 - val_loss: 6.7820 - val_accuracy: 0.6848\n",
            "Epoch 483/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9928 - val_loss: 6.7847 - val_accuracy: 0.6848\n",
            "Epoch 484/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9928 - val_loss: 6.8013 - val_accuracy: 0.6848\n",
            "Epoch 485/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 0.9928 - val_loss: 6.8003 - val_accuracy: 0.6848\n",
            "Epoch 486/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9928 - val_loss: 6.8044 - val_accuracy: 0.6848\n",
            "Epoch 487/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.9928 - val_loss: 6.8044 - val_accuracy: 0.6848\n",
            "Epoch 488/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.9928 - val_loss: 6.8095 - val_accuracy: 0.6848\n",
            "Epoch 489/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 0.9928 - val_loss: 6.8342 - val_accuracy: 0.6848\n",
            "Epoch 490/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0153 - accuracy: 0.9928 - val_loss: 6.8470 - val_accuracy: 0.6848\n",
            "Epoch 491/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0153 - accuracy: 0.9928 - val_loss: 6.8561 - val_accuracy: 0.6848\n",
            "Epoch 492/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0151 - accuracy: 0.9928 - val_loss: 6.8726 - val_accuracy: 0.6848\n",
            "Epoch 493/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0150 - accuracy: 0.9928 - val_loss: 6.8770 - val_accuracy: 0.6848\n",
            "Epoch 494/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0150 - accuracy: 0.9928 - val_loss: 6.8799 - val_accuracy: 0.6902\n",
            "Epoch 495/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0150 - accuracy: 0.9928 - val_loss: 6.8877 - val_accuracy: 0.6902\n",
            "Epoch 496/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 0.9928 - val_loss: 6.8985 - val_accuracy: 0.6848\n",
            "Epoch 497/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 0.9928 - val_loss: 6.9036 - val_accuracy: 0.6848\n",
            "Epoch 498/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 0.9928 - val_loss: 6.9017 - val_accuracy: 0.6848\n",
            "Epoch 499/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 0.9928 - val_loss: 6.9122 - val_accuracy: 0.6848\n",
            "Epoch 500/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 0.9928 - val_loss: 6.9191 - val_accuracy: 0.6848\n",
            "Epoch 501/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0148 - accuracy: 0.9928 - val_loss: 6.9226 - val_accuracy: 0.6848\n",
            "Epoch 502/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0148 - accuracy: 0.9928 - val_loss: 6.9303 - val_accuracy: 0.6848\n",
            "Epoch 503/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0148 - accuracy: 0.9928 - val_loss: 6.9495 - val_accuracy: 0.6848\n",
            "Epoch 504/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 0.9928 - val_loss: 6.9559 - val_accuracy: 0.6848\n",
            "Epoch 505/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9928 - val_loss: 6.9566 - val_accuracy: 0.6848\n",
            "Epoch 506/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9928 - val_loss: 6.9535 - val_accuracy: 0.6848\n",
            "Epoch 507/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9928 - val_loss: 6.9596 - val_accuracy: 0.6848\n",
            "Epoch 508/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9928 - val_loss: 6.9626 - val_accuracy: 0.6848\n",
            "Epoch 509/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9928 - val_loss: 6.9588 - val_accuracy: 0.6848\n",
            "Epoch 510/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9928 - val_loss: 6.9652 - val_accuracy: 0.6848\n",
            "Epoch 511/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 0.9928 - val_loss: 6.9740 - val_accuracy: 0.6793\n",
            "Epoch 512/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 0.9928 - val_loss: 6.9795 - val_accuracy: 0.6793\n",
            "Epoch 513/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0147 - accuracy: 0.9928 - val_loss: 6.9753 - val_accuracy: 0.6793\n",
            "Epoch 514/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0148 - accuracy: 0.9928 - val_loss: 6.9804 - val_accuracy: 0.6793\n",
            "Epoch 515/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9928 - val_loss: 6.9775 - val_accuracy: 0.6793\n",
            "Epoch 516/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9928 - val_loss: 6.9813 - val_accuracy: 0.6793\n",
            "Epoch 517/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9928 - val_loss: 6.9879 - val_accuracy: 0.6793\n",
            "Epoch 518/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9928 - val_loss: 6.9847 - val_accuracy: 0.6793\n",
            "Epoch 519/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 0.9928 - val_loss: 6.9888 - val_accuracy: 0.6793\n",
            "Epoch 520/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9928 - val_loss: 6.9936 - val_accuracy: 0.6793\n",
            "Epoch 521/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9928 - val_loss: 7.0076 - val_accuracy: 0.6848\n",
            "Epoch 522/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 0.9928 - val_loss: 6.9976 - val_accuracy: 0.6793\n",
            "Epoch 523/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9928 - val_loss: 6.9949 - val_accuracy: 0.6793\n",
            "Epoch 524/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 0.9928 - val_loss: 7.0003 - val_accuracy: 0.6793\n",
            "Epoch 525/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9928 - val_loss: 7.0066 - val_accuracy: 0.6793\n",
            "Epoch 526/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 0.9928 - val_loss: 7.0122 - val_accuracy: 0.6793\n",
            "Epoch 527/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9928 - val_loss: 7.0281 - val_accuracy: 0.6793\n",
            "Epoch 528/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0144 - accuracy: 0.9891 - val_loss: 7.0588 - val_accuracy: 0.6793\n",
            "Epoch 529/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0140 - accuracy: 0.9891 - val_loss: 7.0114 - val_accuracy: 0.6793\n",
            "Epoch 530/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 0.9928 - val_loss: 7.0079 - val_accuracy: 0.6793\n",
            "Epoch 531/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0129 - accuracy: 0.9928 - val_loss: 7.0717 - val_accuracy: 0.6848\n",
            "Epoch 532/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9964 - val_loss: 7.0905 - val_accuracy: 0.6848\n",
            "Epoch 533/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.9928 - val_loss: 7.0154 - val_accuracy: 0.6848\n",
            "Epoch 534/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0129 - accuracy: 0.9928 - val_loss: 7.0286 - val_accuracy: 0.6848\n",
            "Epoch 535/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0127 - accuracy: 0.9964 - val_loss: 7.0673 - val_accuracy: 0.6848\n",
            "Epoch 536/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 7.0796 - val_accuracy: 0.6848\n",
            "Epoch 537/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 7.0554 - val_accuracy: 0.6848\n",
            "Epoch 538/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 7.0525 - val_accuracy: 0.6793\n",
            "Epoch 539/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9928 - val_loss: 7.0307 - val_accuracy: 0.6793\n",
            "Epoch 540/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0139 - accuracy: 0.9891 - val_loss: 6.9751 - val_accuracy: 0.6793\n",
            "Epoch 541/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9928 - val_loss: 7.0149 - val_accuracy: 0.6848\n",
            "Epoch 542/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 7.0503 - val_accuracy: 0.6848\n",
            "Epoch 543/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 7.0661 - val_accuracy: 0.6848\n",
            "Epoch 544/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 7.0702 - val_accuracy: 0.6848\n",
            "Epoch 545/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0130 - accuracy: 0.9928 - val_loss: 7.0629 - val_accuracy: 0.6848\n",
            "Epoch 546/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9928 - val_loss: 7.0283 - val_accuracy: 0.6848\n",
            "Epoch 547/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - accuracy: 0.9891 - val_loss: 7.0311 - val_accuracy: 0.6848\n",
            "Epoch 548/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9928 - val_loss: 7.0643 - val_accuracy: 0.6848\n",
            "Epoch 549/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 7.0848 - val_accuracy: 0.6848\n",
            "Epoch 550/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9964 - val_loss: 7.0926 - val_accuracy: 0.6848\n",
            "Epoch 551/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 7.0515 - val_accuracy: 0.6848\n",
            "Epoch 552/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9928 - val_loss: 7.0623 - val_accuracy: 0.6848\n",
            "Epoch 553/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 7.0572 - val_accuracy: 0.6848\n",
            "Epoch 554/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 7.1037 - val_accuracy: 0.6848\n",
            "Epoch 555/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 7.1439 - val_accuracy: 0.6848\n",
            "Epoch 556/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 0.9928 - val_loss: 7.0550 - val_accuracy: 0.6848\n",
            "Epoch 557/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 7.0644 - val_accuracy: 0.6848\n",
            "Epoch 558/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0123 - accuracy: 0.9928 - val_loss: 7.0692 - val_accuracy: 0.6848\n",
            "Epoch 559/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 7.1035 - val_accuracy: 0.6848\n",
            "Epoch 560/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 7.1195 - val_accuracy: 0.6848\n",
            "Epoch 561/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 0.9928 - val_loss: 7.1267 - val_accuracy: 0.6848\n",
            "Epoch 562/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 7.1643 - val_accuracy: 0.6848\n",
            "Epoch 563/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.9928 - val_loss: 7.1280 - val_accuracy: 0.6848\n",
            "Epoch 564/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9928 - val_loss: 7.1514 - val_accuracy: 0.6793\n",
            "Epoch 565/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.9891 - val_loss: 7.1339 - val_accuracy: 0.6848\n",
            "Epoch 566/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0122 - accuracy: 0.9928 - val_loss: 7.1058 - val_accuracy: 0.6848\n",
            "Epoch 567/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 7.1250 - val_accuracy: 0.6848\n",
            "Epoch 568/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0119 - accuracy: 0.9928 - val_loss: 7.1538 - val_accuracy: 0.6848\n",
            "Epoch 569/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0125 - accuracy: 0.9928 - val_loss: 7.1612 - val_accuracy: 0.6848\n",
            "Epoch 570/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9928 - val_loss: 7.1577 - val_accuracy: 0.6848\n",
            "Epoch 571/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 7.1773 - val_accuracy: 0.6793\n",
            "Epoch 572/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 0.9928 - val_loss: 7.1724 - val_accuracy: 0.6793\n",
            "Epoch 573/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0127 - accuracy: 0.9891 - val_loss: 7.1190 - val_accuracy: 0.6848\n",
            "Epoch 574/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.9928 - val_loss: 7.1424 - val_accuracy: 0.6848\n",
            "Epoch 575/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.9928 - val_loss: 7.1632 - val_accuracy: 0.6848\n",
            "Epoch 576/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 7.2138 - val_accuracy: 0.6793\n",
            "Epoch 577/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9891 - val_loss: 7.1955 - val_accuracy: 0.6793\n",
            "Epoch 578/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 7.1606 - val_accuracy: 0.6848\n",
            "Epoch 579/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.9928 - val_loss: 7.2057 - val_accuracy: 0.6793\n",
            "Epoch 580/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0127 - accuracy: 0.9928 - val_loss: 7.1729 - val_accuracy: 0.6848\n",
            "Epoch 581/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 7.1329 - val_accuracy: 0.6848\n",
            "Epoch 582/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0121 - accuracy: 0.9928 - val_loss: 7.1420 - val_accuracy: 0.6848\n",
            "Epoch 583/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.9928 - val_loss: 7.1975 - val_accuracy: 0.6848\n",
            "Epoch 584/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 7.1564 - val_accuracy: 0.6848\n",
            "Epoch 585/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 7.1918 - val_accuracy: 0.6793\n",
            "Epoch 586/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.9928 - val_loss: 7.1942 - val_accuracy: 0.6848\n",
            "Epoch 587/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 7.1852 - val_accuracy: 0.6848\n",
            "Epoch 588/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 7.1837 - val_accuracy: 0.6848\n",
            "Epoch 589/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9928 - val_loss: 7.2183 - val_accuracy: 0.6848\n",
            "Epoch 590/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 7.2409 - val_accuracy: 0.6793\n",
            "Epoch 591/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9928 - val_loss: 7.2283 - val_accuracy: 0.6793\n",
            "Epoch 592/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 7.2039 - val_accuracy: 0.6848\n",
            "Epoch 593/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.9928 - val_loss: 7.2447 - val_accuracy: 0.6848\n",
            "Epoch 594/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0123 - accuracy: 0.9928 - val_loss: 7.2251 - val_accuracy: 0.6793\n",
            "Epoch 595/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 7.2367 - val_accuracy: 0.6793\n",
            "Epoch 596/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9928 - val_loss: 7.1615 - val_accuracy: 0.6793\n",
            "Epoch 597/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9928 - val_loss: 7.2016 - val_accuracy: 0.6848\n",
            "Epoch 598/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9928 - val_loss: 7.2344 - val_accuracy: 0.6793\n",
            "Epoch 599/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9928 - val_loss: 7.3156 - val_accuracy: 0.6848\n",
            "Epoch 600/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9928 - val_loss: 7.2383 - val_accuracy: 0.6793\n",
            "Epoch 601/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9928 - val_loss: 7.2514 - val_accuracy: 0.6793\n",
            "Epoch 602/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0123 - accuracy: 0.9928 - val_loss: 7.2525 - val_accuracy: 0.6739\n",
            "Epoch 603/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0114 - accuracy: 0.9928 - val_loss: 7.2236 - val_accuracy: 0.6793\n",
            "Epoch 604/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9928 - val_loss: 7.2172 - val_accuracy: 0.6793\n",
            "Epoch 605/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 7.2620 - val_accuracy: 0.6739\n",
            "Epoch 606/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 7.2186 - val_accuracy: 0.6739\n",
            "Epoch 607/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9891 - val_loss: 7.2423 - val_accuracy: 0.6739\n",
            "Epoch 608/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9891 - val_loss: 7.2507 - val_accuracy: 0.6793\n",
            "Epoch 609/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9928 - val_loss: 7.2610 - val_accuracy: 0.6793\n",
            "Epoch 610/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 0.9928 - val_loss: 7.3102 - val_accuracy: 0.6739\n",
            "Epoch 611/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.9928 - val_loss: 7.2771 - val_accuracy: 0.6793\n",
            "Epoch 612/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9928 - val_loss: 7.2788 - val_accuracy: 0.6793\n",
            "Epoch 613/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9928 - val_loss: 7.3118 - val_accuracy: 0.6739\n",
            "Epoch 614/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 7.3595 - val_accuracy: 0.6739\n",
            "Epoch 615/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - accuracy: 0.9928 - val_loss: 7.3198 - val_accuracy: 0.6739\n",
            "Epoch 616/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.9928 - val_loss: 7.2838 - val_accuracy: 0.6793\n",
            "Epoch 617/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9928 - val_loss: 7.3417 - val_accuracy: 0.6739\n",
            "Epoch 618/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 0.9928 - val_loss: 7.3219 - val_accuracy: 0.6739\n",
            "Epoch 619/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9928 - val_loss: 7.3612 - val_accuracy: 0.6739\n",
            "Epoch 620/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 7.3705 - val_accuracy: 0.6793\n",
            "Epoch 621/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0123 - accuracy: 0.9928 - val_loss: 7.3649 - val_accuracy: 0.6793\n",
            "Epoch 622/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 7.2403 - val_accuracy: 0.6739\n",
            "Epoch 623/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0122 - accuracy: 0.9928 - val_loss: 7.2557 - val_accuracy: 0.6793\n",
            "Epoch 624/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9928 - val_loss: 7.2803 - val_accuracy: 0.6793\n",
            "Epoch 625/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 7.3222 - val_accuracy: 0.6848\n",
            "Epoch 626/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9928 - val_loss: 7.3484 - val_accuracy: 0.6739\n",
            "Epoch 627/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9928 - val_loss: 7.3453 - val_accuracy: 0.6739\n",
            "Epoch 628/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9928 - val_loss: 7.3233 - val_accuracy: 0.6793\n",
            "Epoch 629/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 7.3360 - val_accuracy: 0.6793\n",
            "Epoch 630/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 7.3988 - val_accuracy: 0.6848\n",
            "Epoch 631/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9891 - val_loss: 7.3700 - val_accuracy: 0.6739\n",
            "Epoch 632/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.9928 - val_loss: 7.3234 - val_accuracy: 0.6793\n",
            "Epoch 633/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9928 - val_loss: 7.5019 - val_accuracy: 0.6848\n",
            "Epoch 634/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0151 - accuracy: 0.9891 - val_loss: 7.3217 - val_accuracy: 0.6739\n",
            "Epoch 635/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 7.3503 - val_accuracy: 0.6685\n",
            "Epoch 636/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9928 - val_loss: 7.3620 - val_accuracy: 0.6793\n",
            "Epoch 637/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 0.9928 - val_loss: 7.3536 - val_accuracy: 0.6739\n",
            "Epoch 638/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 0.9928 - val_loss: 7.3887 - val_accuracy: 0.6685\n",
            "Epoch 639/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 7.3965 - val_accuracy: 0.6685\n",
            "Epoch 640/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9928 - val_loss: 7.3851 - val_accuracy: 0.6685\n",
            "Epoch 641/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 7.3626 - val_accuracy: 0.6685\n",
            "Epoch 642/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 7.4609 - val_accuracy: 0.6739\n",
            "Epoch 643/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9928 - val_loss: 7.4016 - val_accuracy: 0.6685\n",
            "Epoch 644/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 7.3906 - val_accuracy: 0.6685\n",
            "Epoch 645/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9928 - val_loss: 7.4156 - val_accuracy: 0.6685\n",
            "Epoch 646/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 7.4073 - val_accuracy: 0.6685\n",
            "Epoch 647/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0111 - accuracy: 0.9928 - val_loss: 7.4082 - val_accuracy: 0.6685\n",
            "Epoch 648/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0110 - accuracy: 0.9928 - val_loss: 7.4162 - val_accuracy: 0.6685\n",
            "Epoch 649/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9928 - val_loss: 7.4105 - val_accuracy: 0.6685\n",
            "Epoch 650/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9928 - val_loss: 7.4534 - val_accuracy: 0.6739\n",
            "Epoch 651/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9891 - val_loss: 7.4689 - val_accuracy: 0.6739\n",
            "Epoch 652/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9928 - val_loss: 7.4395 - val_accuracy: 0.6685\n",
            "Epoch 653/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9928 - val_loss: 7.5070 - val_accuracy: 0.6793\n",
            "Epoch 654/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9928 - val_loss: 7.4473 - val_accuracy: 0.6685\n",
            "Epoch 655/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9928 - val_loss: 7.4761 - val_accuracy: 0.6739\n",
            "Epoch 656/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9891 - val_loss: 7.4921 - val_accuracy: 0.6685\n",
            "Epoch 657/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 7.4855 - val_accuracy: 0.6685\n",
            "Epoch 658/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 7.4892 - val_accuracy: 0.6739\n",
            "Epoch 659/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9928 - val_loss: 7.4753 - val_accuracy: 0.6685\n",
            "Epoch 660/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9928 - val_loss: 7.4934 - val_accuracy: 0.6685\n",
            "Epoch 661/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 0.9928 - val_loss: 7.5172 - val_accuracy: 0.6685\n",
            "Epoch 662/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9891 - val_loss: 7.4959 - val_accuracy: 0.6685\n",
            "Epoch 663/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9928 - val_loss: 7.5107 - val_accuracy: 0.6685\n",
            "Epoch 664/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9928 - val_loss: 7.5296 - val_accuracy: 0.6739\n",
            "Epoch 665/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 0.9928 - val_loss: 7.5147 - val_accuracy: 0.6685\n",
            "Epoch 666/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 7.5334 - val_accuracy: 0.6739\n",
            "Epoch 667/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0172 - accuracy: 0.9891 - val_loss: 7.5901 - val_accuracy: 0.6793\n",
            "Epoch 668/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 7.4383 - val_accuracy: 0.6739\n",
            "Epoch 669/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 7.4080 - val_accuracy: 0.6739\n",
            "Epoch 670/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9928 - val_loss: 7.3362 - val_accuracy: 0.6793\n",
            "Epoch 671/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9928 - val_loss: 7.3065 - val_accuracy: 0.6685\n",
            "Epoch 672/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 7.3810 - val_accuracy: 0.6685\n",
            "Epoch 673/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 7.3985 - val_accuracy: 0.6685\n",
            "Epoch 674/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 7.4202 - val_accuracy: 0.6685\n",
            "Epoch 675/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 7.4189 - val_accuracy: 0.6685\n",
            "Epoch 676/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 7.4557 - val_accuracy: 0.6739\n",
            "Epoch 677/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 7.4480 - val_accuracy: 0.6739\n",
            "Epoch 678/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 7.4497 - val_accuracy: 0.6685\n",
            "Epoch 679/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 7.4655 - val_accuracy: 0.6685\n",
            "Epoch 680/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 7.5819 - val_accuracy: 0.6793\n",
            "Epoch 681/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 7.5320 - val_accuracy: 0.6685\n",
            "Epoch 682/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 7.4408 - val_accuracy: 0.6630\n",
            "Epoch 683/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 7.4970 - val_accuracy: 0.6630\n",
            "Epoch 684/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9891 - val_loss: 7.5418 - val_accuracy: 0.6739\n",
            "Epoch 685/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9928 - val_loss: 7.5003 - val_accuracy: 0.6685\n",
            "Epoch 686/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9928 - val_loss: 7.5569 - val_accuracy: 0.6685\n",
            "Epoch 687/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 0.9891 - val_loss: 7.5763 - val_accuracy: 0.6685\n",
            "Epoch 688/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 7.5414 - val_accuracy: 0.6685\n",
            "Epoch 689/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9928 - val_loss: 7.5341 - val_accuracy: 0.6630\n",
            "Epoch 690/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 7.5643 - val_accuracy: 0.6630\n",
            "Epoch 691/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0097 - accuracy: 0.9964 - val_loss: 7.5658 - val_accuracy: 0.6685\n",
            "Epoch 692/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9928 - val_loss: 7.5882 - val_accuracy: 0.6630\n",
            "Epoch 693/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 7.5627 - val_accuracy: 0.6685\n",
            "Epoch 694/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9964 - val_loss: 7.5916 - val_accuracy: 0.6685\n",
            "Epoch 695/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9928 - val_loss: 7.5735 - val_accuracy: 0.6685\n",
            "Epoch 696/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 7.5700 - val_accuracy: 0.6685\n",
            "Epoch 697/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9928 - val_loss: 7.6024 - val_accuracy: 0.6630\n",
            "Epoch 698/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0097 - accuracy: 0.9964 - val_loss: 7.6284 - val_accuracy: 0.6685\n",
            "Epoch 699/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9928 - val_loss: 7.6162 - val_accuracy: 0.6630\n",
            "Epoch 700/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0106 - accuracy: 0.9928 - val_loss: 7.6412 - val_accuracy: 0.6685\n",
            "Epoch 701/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9928 - val_loss: 7.5822 - val_accuracy: 0.6685\n",
            "Epoch 702/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0114 - accuracy: 0.9928 - val_loss: 7.6423 - val_accuracy: 0.6685\n",
            "Epoch 703/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0123 - accuracy: 0.9928 - val_loss: 7.6101 - val_accuracy: 0.6739\n",
            "Epoch 704/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 7.5525 - val_accuracy: 0.6630\n",
            "Epoch 705/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 7.6019 - val_accuracy: 0.6685\n",
            "Epoch 706/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0099 - accuracy: 0.9964 - val_loss: 7.6109 - val_accuracy: 0.6685\n",
            "Epoch 707/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9964 - val_loss: 7.6323 - val_accuracy: 0.6685\n",
            "Epoch 708/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0098 - accuracy: 0.9964 - val_loss: 7.5951 - val_accuracy: 0.6685\n",
            "Epoch 709/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9964 - val_loss: 7.6466 - val_accuracy: 0.6630\n",
            "Epoch 710/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 7.6497 - val_accuracy: 0.6630\n",
            "Epoch 711/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 0.9964 - val_loss: 7.6545 - val_accuracy: 0.6630\n",
            "Epoch 712/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 7.6562 - val_accuracy: 0.6685\n",
            "Epoch 713/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0098 - accuracy: 0.9928 - val_loss: 7.6676 - val_accuracy: 0.6630\n",
            "Epoch 714/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 0.9928 - val_loss: 7.6600 - val_accuracy: 0.6685\n",
            "Epoch 715/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0113 - accuracy: 0.9891 - val_loss: 7.6915 - val_accuracy: 0.6630\n",
            "Epoch 716/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9964 - val_loss: 7.6785 - val_accuracy: 0.6685\n",
            "Epoch 717/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9928 - val_loss: 7.7042 - val_accuracy: 0.6630\n",
            "Epoch 718/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 7.6820 - val_accuracy: 0.6685\n",
            "Epoch 719/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 0.9928 - val_loss: 7.7312 - val_accuracy: 0.6685\n",
            "Epoch 720/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.9964 - val_loss: 7.7074 - val_accuracy: 0.6685\n",
            "Epoch 721/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 0.9964 - val_loss: 7.7001 - val_accuracy: 0.6685\n",
            "Epoch 722/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0108 - accuracy: 0.9928 - val_loss: 7.7196 - val_accuracy: 0.6630\n",
            "Epoch 723/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 7.7467 - val_accuracy: 0.6630\n",
            "Epoch 724/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9928 - val_loss: 7.6916 - val_accuracy: 0.6685\n",
            "Epoch 725/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9928 - val_loss: 7.7492 - val_accuracy: 0.6685\n",
            "Epoch 726/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9928 - val_loss: 7.7974 - val_accuracy: 0.6685\n",
            "Epoch 727/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - accuracy: 0.9928 - val_loss: 7.7725 - val_accuracy: 0.6630\n",
            "Epoch 728/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9928 - val_loss: 7.6892 - val_accuracy: 0.6630\n",
            "Epoch 729/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 0.9964 - val_loss: 7.7479 - val_accuracy: 0.6630\n",
            "Epoch 730/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 0.9964 - val_loss: 7.7634 - val_accuracy: 0.6685\n",
            "Epoch 731/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 7.7515 - val_accuracy: 0.6685\n",
            "Epoch 732/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9964 - val_loss: 7.7603 - val_accuracy: 0.6685\n",
            "Epoch 733/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0106 - accuracy: 0.9928 - val_loss: 7.7235 - val_accuracy: 0.6685\n",
            "Epoch 734/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 0.9928 - val_loss: 7.8002 - val_accuracy: 0.6685\n",
            "Epoch 735/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9928 - val_loss: 7.7596 - val_accuracy: 0.6685\n",
            "Epoch 736/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0094 - accuracy: 0.9964 - val_loss: 7.7537 - val_accuracy: 0.6685\n",
            "Epoch 737/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - accuracy: 0.9928 - val_loss: 7.8013 - val_accuracy: 0.6685\n",
            "Epoch 738/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9964 - val_loss: 7.7772 - val_accuracy: 0.6685\n",
            "Epoch 739/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 7.7921 - val_accuracy: 0.6630\n",
            "Epoch 740/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 7.7933 - val_accuracy: 0.6685\n",
            "Epoch 741/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 0.9928 - val_loss: 7.8045 - val_accuracy: 0.6685\n",
            "Epoch 742/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 0.9928 - val_loss: 7.8393 - val_accuracy: 0.6685\n",
            "Epoch 743/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.9964 - val_loss: 7.8076 - val_accuracy: 0.6685\n",
            "Epoch 744/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9964 - val_loss: 7.8318 - val_accuracy: 0.6685\n",
            "Epoch 745/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 0.9964 - val_loss: 7.8406 - val_accuracy: 0.6685\n",
            "Epoch 746/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 0.9964 - val_loss: 7.8265 - val_accuracy: 0.6630\n",
            "Epoch 747/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0090 - accuracy: 0.9964 - val_loss: 7.8293 - val_accuracy: 0.6685\n",
            "Epoch 748/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9964 - val_loss: 7.8444 - val_accuracy: 0.6685\n",
            "Epoch 749/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 7.8530 - val_accuracy: 0.6630\n",
            "Epoch 750/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9964 - val_loss: 7.8697 - val_accuracy: 0.6685\n",
            "Epoch 751/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - accuracy: 0.9964 - val_loss: 7.9201 - val_accuracy: 0.6685\n",
            "Epoch 752/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 0.9964 - val_loss: 7.8812 - val_accuracy: 0.6685\n",
            "Epoch 753/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 7.8747 - val_accuracy: 0.6685\n",
            "Epoch 754/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 0.9964 - val_loss: 7.9029 - val_accuracy: 0.6685\n",
            "Epoch 755/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 0.9964 - val_loss: 7.8730 - val_accuracy: 0.6685\n",
            "Epoch 756/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9964 - val_loss: 7.8904 - val_accuracy: 0.6685\n",
            "Epoch 757/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0087 - accuracy: 0.9964 - val_loss: 7.9056 - val_accuracy: 0.6685\n",
            "Epoch 758/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 0.9964 - val_loss: 7.9105 - val_accuracy: 0.6685\n",
            "Epoch 759/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9964 - val_loss: 7.9257 - val_accuracy: 0.6685\n",
            "Epoch 760/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 7.9432 - val_accuracy: 0.6685\n",
            "Epoch 761/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 0.9964 - val_loss: 7.9205 - val_accuracy: 0.6739\n",
            "Epoch 762/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 0.9964 - val_loss: 7.9286 - val_accuracy: 0.6685\n",
            "Epoch 763/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9964 - val_loss: 7.9497 - val_accuracy: 0.6685\n",
            "Epoch 764/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9964 - val_loss: 7.9296 - val_accuracy: 0.6685\n",
            "Epoch 765/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9964 - val_loss: 7.9553 - val_accuracy: 0.6739\n",
            "Epoch 766/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - accuracy: 0.9964 - val_loss: 8.0009 - val_accuracy: 0.6739\n",
            "Epoch 767/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 0.9928 - val_loss: 7.9680 - val_accuracy: 0.6739\n",
            "Epoch 768/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.9891 - val_loss: 7.9557 - val_accuracy: 0.6685\n",
            "Epoch 769/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 7.9334 - val_accuracy: 0.6685\n",
            "Epoch 770/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 0.9964 - val_loss: 7.8856 - val_accuracy: 0.6793\n",
            "Epoch 771/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.9964 - val_loss: 7.9867 - val_accuracy: 0.6848\n",
            "Epoch 772/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 0.9964 - val_loss: 7.9663 - val_accuracy: 0.6793\n",
            "Epoch 773/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 0.9964 - val_loss: 7.9830 - val_accuracy: 0.6739\n",
            "Epoch 774/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 7.9679 - val_accuracy: 0.6793\n",
            "Epoch 775/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 7.9639 - val_accuracy: 0.6793\n",
            "Epoch 776/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 7.9635 - val_accuracy: 0.6685\n",
            "Epoch 777/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 7.9761 - val_accuracy: 0.6793\n",
            "Epoch 778/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9964 - val_loss: 7.9727 - val_accuracy: 0.6739\n",
            "Epoch 779/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0090 - accuracy: 0.9964 - val_loss: 8.0062 - val_accuracy: 0.6793\n",
            "Epoch 780/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9928 - val_loss: 7.9880 - val_accuracy: 0.6793\n",
            "Epoch 781/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9964 - val_loss: 8.0551 - val_accuracy: 0.6793\n",
            "Epoch 782/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 7.9869 - val_accuracy: 0.6739\n",
            "Epoch 783/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 8.0292 - val_accuracy: 0.6685\n",
            "Epoch 784/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 8.0251 - val_accuracy: 0.6793\n",
            "Epoch 785/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9964 - val_loss: 8.0077 - val_accuracy: 0.6793\n",
            "Epoch 786/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9964 - val_loss: 8.0687 - val_accuracy: 0.6739\n",
            "Epoch 787/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 0.9964 - val_loss: 8.0368 - val_accuracy: 0.6793\n",
            "Epoch 788/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9964 - val_loss: 8.0192 - val_accuracy: 0.6739\n",
            "Epoch 789/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0087 - accuracy: 0.9964 - val_loss: 8.0713 - val_accuracy: 0.6793\n",
            "Epoch 790/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9928 - val_loss: 8.0834 - val_accuracy: 0.6739\n",
            "Epoch 791/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9928 - val_loss: 8.0389 - val_accuracy: 0.6685\n",
            "Epoch 792/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9964 - val_loss: 8.0976 - val_accuracy: 0.6739\n",
            "Epoch 793/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0096 - accuracy: 0.9964 - val_loss: 8.0820 - val_accuracy: 0.6793\n",
            "Epoch 794/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.9928 - val_loss: 7.9760 - val_accuracy: 0.6685\n",
            "Epoch 795/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 8.0494 - val_accuracy: 0.6793\n",
            "Epoch 796/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - accuracy: 0.9964 - val_loss: 8.0962 - val_accuracy: 0.6848\n",
            "Epoch 797/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0084 - accuracy: 0.9964 - val_loss: 8.0492 - val_accuracy: 0.6685\n",
            "Epoch 798/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0093 - accuracy: 0.9964 - val_loss: 8.0863 - val_accuracy: 0.6793\n",
            "Epoch 799/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9928 - val_loss: 8.0835 - val_accuracy: 0.6630\n",
            "Epoch 800/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 0.9964 - val_loss: 8.1182 - val_accuracy: 0.6793\n",
            "Epoch 801/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 7.6903 - val_accuracy: 0.6630\n",
            "Epoch 802/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0417 - accuracy: 0.9855 - val_loss: 8.0102 - val_accuracy: 0.7065\n",
            "Epoch 803/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0494 - accuracy: 0.9855 - val_loss: 8.0659 - val_accuracy: 0.6957\n",
            "Epoch 804/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0233 - accuracy: 0.9891 - val_loss: 7.7565 - val_accuracy: 0.6902\n",
            "Epoch 805/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0308 - accuracy: 0.9855 - val_loss: 8.0712 - val_accuracy: 0.6902\n",
            "Epoch 806/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0258 - accuracy: 0.9891 - val_loss: 7.8764 - val_accuracy: 0.6957\n",
            "Epoch 807/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0202 - accuracy: 0.9891 - val_loss: 7.6354 - val_accuracy: 0.6957\n",
            "Epoch 808/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0110 - accuracy: 0.9928 - val_loss: 7.7037 - val_accuracy: 0.6902\n",
            "Epoch 809/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 7.7917 - val_accuracy: 0.6902\n",
            "Epoch 810/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9964 - val_loss: 7.7942 - val_accuracy: 0.6902\n",
            "Epoch 811/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0090 - accuracy: 0.9964 - val_loss: 7.8161 - val_accuracy: 0.6902\n",
            "Epoch 812/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 0.9928 - val_loss: 7.8507 - val_accuracy: 0.6902\n",
            "Epoch 813/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 7.8000 - val_accuracy: 0.6902\n",
            "Epoch 814/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 7.7825 - val_accuracy: 0.6902\n",
            "Epoch 815/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 0.9964 - val_loss: 7.8031 - val_accuracy: 0.6902\n",
            "Epoch 816/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0090 - accuracy: 0.9964 - val_loss: 7.8202 - val_accuracy: 0.6902\n",
            "Epoch 817/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 7.7880 - val_accuracy: 0.6902\n",
            "Epoch 818/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 7.8235 - val_accuracy: 0.6848\n",
            "Epoch 819/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 7.7954 - val_accuracy: 0.6902\n",
            "Epoch 820/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - accuracy: 0.9964 - val_loss: 7.8164 - val_accuracy: 0.6848\n",
            "Epoch 821/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 7.8158 - val_accuracy: 0.6793\n",
            "Epoch 822/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 7.8083 - val_accuracy: 0.6848\n",
            "Epoch 823/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 7.7765 - val_accuracy: 0.6793\n",
            "Epoch 824/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9964 - val_loss: 7.8186 - val_accuracy: 0.6848\n",
            "Epoch 825/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0090 - accuracy: 0.9964 - val_loss: 7.8343 - val_accuracy: 0.6793\n",
            "Epoch 826/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 7.8085 - val_accuracy: 0.6793\n",
            "Epoch 827/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - accuracy: 0.9964 - val_loss: 7.7960 - val_accuracy: 0.6793\n",
            "Epoch 828/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 0.9964 - val_loss: 7.8308 - val_accuracy: 0.6793\n",
            "Epoch 829/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 7.8160 - val_accuracy: 0.6793\n",
            "Epoch 830/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9964 - val_loss: 7.8080 - val_accuracy: 0.6793\n",
            "Epoch 831/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9964 - val_loss: 7.8263 - val_accuracy: 0.6793\n",
            "Epoch 832/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 7.8164 - val_accuracy: 0.6793\n",
            "Epoch 833/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 7.8177 - val_accuracy: 0.6793\n",
            "Epoch 834/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9964 - val_loss: 7.8246 - val_accuracy: 0.6793\n",
            "Epoch 835/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 0.9964 - val_loss: 7.8325 - val_accuracy: 0.6793\n",
            "Epoch 836/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 7.8255 - val_accuracy: 0.6848\n",
            "Epoch 837/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9964 - val_loss: 7.8323 - val_accuracy: 0.6848\n",
            "Epoch 838/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0083 - accuracy: 0.9964 - val_loss: 7.8272 - val_accuracy: 0.6848\n",
            "Epoch 839/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 0.9964 - val_loss: 7.8250 - val_accuracy: 0.6848\n",
            "Epoch 840/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 7.8475 - val_accuracy: 0.6848\n",
            "Epoch 841/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 7.8380 - val_accuracy: 0.6848\n",
            "Epoch 842/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 0.9964 - val_loss: 7.8365 - val_accuracy: 0.6848\n",
            "Epoch 843/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 0.9964 - val_loss: 7.8217 - val_accuracy: 0.6848\n",
            "Epoch 844/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0159 - accuracy: 0.9928 - val_loss: 7.9837 - val_accuracy: 0.6793\n",
            "Epoch 845/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0192 - accuracy: 0.9964 - val_loss: 7.4617 - val_accuracy: 0.6576\n",
            "Epoch 846/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0209 - accuracy: 0.9891 - val_loss: 7.6569 - val_accuracy: 0.6685\n",
            "Epoch 847/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0143 - accuracy: 0.9928 - val_loss: 7.9125 - val_accuracy: 0.6848\n",
            "Epoch 848/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0115 - accuracy: 0.9928 - val_loss: 8.0268 - val_accuracy: 0.6902\n",
            "Epoch 849/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - accuracy: 0.9964 - val_loss: 8.0631 - val_accuracy: 0.6902\n",
            "Epoch 850/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0087 - accuracy: 0.9964 - val_loss: 8.0343 - val_accuracy: 0.6957\n",
            "Epoch 851/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9964 - val_loss: 8.0001 - val_accuracy: 0.6902\n",
            "Epoch 852/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - accuracy: 0.9964 - val_loss: 7.9894 - val_accuracy: 0.6902\n",
            "Epoch 853/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0083 - accuracy: 0.9964 - val_loss: 8.0288 - val_accuracy: 0.6902\n",
            "Epoch 854/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9964 - val_loss: 8.0114 - val_accuracy: 0.6957\n",
            "Epoch 855/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 0.9964 - val_loss: 8.0290 - val_accuracy: 0.6957\n",
            "Epoch 856/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - accuracy: 0.9964 - val_loss: 8.0368 - val_accuracy: 0.6902\n",
            "Epoch 857/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0081 - accuracy: 0.9964 - val_loss: 7.9978 - val_accuracy: 0.6902\n",
            "Epoch 858/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 0.9964 - val_loss: 8.0122 - val_accuracy: 0.6902\n",
            "Epoch 859/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 0.9964 - val_loss: 8.0157 - val_accuracy: 0.6902\n",
            "Epoch 860/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 0.9964 - val_loss: 8.0211 - val_accuracy: 0.6902\n",
            "Epoch 861/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 0.9964 - val_loss: 8.0240 - val_accuracy: 0.6902\n",
            "Epoch 862/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0082 - accuracy: 0.9964 - val_loss: 8.0287 - val_accuracy: 0.6848\n",
            "Epoch 863/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - accuracy: 0.9964 - val_loss: 8.0389 - val_accuracy: 0.6902\n",
            "Epoch 864/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9964 - val_loss: 8.0094 - val_accuracy: 0.6848\n",
            "Epoch 865/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 0.9964 - val_loss: 8.0690 - val_accuracy: 0.6848\n",
            "Epoch 866/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9964 - val_loss: 8.0323 - val_accuracy: 0.6848\n",
            "Epoch 867/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0083 - accuracy: 0.9964 - val_loss: 8.0637 - val_accuracy: 0.6848\n",
            "Epoch 868/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 0.9964 - val_loss: 8.0451 - val_accuracy: 0.6848\n",
            "Epoch 869/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9964 - val_loss: 8.0220 - val_accuracy: 0.6848\n",
            "Epoch 870/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9964 - val_loss: 8.0265 - val_accuracy: 0.6848\n",
            "Epoch 871/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 0.9964 - val_loss: 8.0377 - val_accuracy: 0.6848\n",
            "Epoch 872/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 8.0355 - val_accuracy: 0.6848\n",
            "Epoch 873/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 8.0528 - val_accuracy: 0.6848\n",
            "Epoch 874/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 0.9964 - val_loss: 8.0219 - val_accuracy: 0.6848\n",
            "Epoch 875/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0082 - accuracy: 0.9964 - val_loss: 8.0506 - val_accuracy: 0.6848\n",
            "Epoch 876/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0079 - accuracy: 0.9964 - val_loss: 8.0212 - val_accuracy: 0.6848\n",
            "Epoch 877/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 8.0335 - val_accuracy: 0.6848\n",
            "Epoch 878/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 8.0405 - val_accuracy: 0.6848\n",
            "Epoch 879/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9964 - val_loss: 8.0327 - val_accuracy: 0.6793\n",
            "Epoch 880/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 8.0413 - val_accuracy: 0.6848\n",
            "Epoch 881/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 8.0516 - val_accuracy: 0.6848\n",
            "Epoch 882/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 8.0266 - val_accuracy: 0.6793\n",
            "Epoch 883/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 8.0688 - val_accuracy: 0.6848\n",
            "Epoch 884/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 8.0382 - val_accuracy: 0.6793\n",
            "Epoch 885/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 8.0449 - val_accuracy: 0.6848\n",
            "Epoch 886/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 8.2147 - val_accuracy: 0.6848\n",
            "Epoch 887/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 8.0963 - val_accuracy: 0.6848\n",
            "Epoch 888/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 8.0394 - val_accuracy: 0.6793\n",
            "Epoch 889/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 8.0658 - val_accuracy: 0.6848\n",
            "Epoch 890/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 8.0599 - val_accuracy: 0.6793\n",
            "Epoch 891/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 8.0793 - val_accuracy: 0.6848\n",
            "Epoch 892/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 8.1147 - val_accuracy: 0.6848\n",
            "Epoch 893/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 8.0665 - val_accuracy: 0.6793\n",
            "Epoch 894/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 8.0870 - val_accuracy: 0.6793\n",
            "Epoch 895/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 8.0719 - val_accuracy: 0.6793\n",
            "Epoch 896/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 0.9964 - val_loss: 8.1035 - val_accuracy: 0.6793\n",
            "Epoch 897/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - accuracy: 0.9964 - val_loss: 8.1025 - val_accuracy: 0.6793\n",
            "Epoch 898/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 0.9964 - val_loss: 8.0580 - val_accuracy: 0.6848\n",
            "Epoch 899/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0083 - accuracy: 0.9964 - val_loss: 8.0799 - val_accuracy: 0.6848\n",
            "Epoch 900/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 0.9964 - val_loss: 8.0750 - val_accuracy: 0.6848\n",
            "Epoch 901/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 0.9964 - val_loss: 8.0878 - val_accuracy: 0.6793\n",
            "Epoch 902/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 0.9928 - val_loss: 7.9660 - val_accuracy: 0.6685\n",
            "Epoch 903/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9928 - val_loss: 8.0683 - val_accuracy: 0.6793\n",
            "Epoch 904/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0084 - accuracy: 0.9964 - val_loss: 8.1467 - val_accuracy: 0.6848\n",
            "Epoch 905/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 0.9964 - val_loss: 8.1503 - val_accuracy: 0.6848\n",
            "Epoch 906/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 0.9964 - val_loss: 8.0991 - val_accuracy: 0.6848\n",
            "Epoch 907/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 8.1055 - val_accuracy: 0.6848\n",
            "Epoch 908/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 8.1428 - val_accuracy: 0.6848\n",
            "Epoch 909/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 8.1307 - val_accuracy: 0.6848\n",
            "Epoch 910/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 8.1230 - val_accuracy: 0.6848\n",
            "Epoch 911/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 0.9964 - val_loss: 8.1204 - val_accuracy: 0.6848\n",
            "Epoch 912/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 8.1450 - val_accuracy: 0.6848\n",
            "Epoch 913/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0079 - accuracy: 0.9964 - val_loss: 8.1405 - val_accuracy: 0.6848\n",
            "Epoch 914/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0077 - accuracy: 0.9964 - val_loss: 8.1475 - val_accuracy: 0.6848\n",
            "Epoch 915/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 8.1486 - val_accuracy: 0.6848\n",
            "Epoch 916/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9964 - val_loss: 8.2194 - val_accuracy: 0.6793\n",
            "Epoch 917/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 0.9964 - val_loss: 8.1889 - val_accuracy: 0.6793\n",
            "Epoch 918/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.9964 - val_loss: 8.1463 - val_accuracy: 0.6793\n",
            "Epoch 919/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 8.1546 - val_accuracy: 0.6793\n",
            "Epoch 920/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 8.1546 - val_accuracy: 0.6793\n",
            "Epoch 921/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 8.1621 - val_accuracy: 0.6848\n",
            "Epoch 922/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.9964 - val_loss: 8.1646 - val_accuracy: 0.6848\n",
            "Epoch 923/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 8.1715 - val_accuracy: 0.6848\n",
            "Epoch 924/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 8.1715 - val_accuracy: 0.6848\n",
            "Epoch 925/1000\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 8.2125 - val_accuracy: 0.6848\n",
            "Epoch 926/1000\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 8.1974 - val_accuracy: 0.6848\n",
            "Epoch 927/1000\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0080 - accuracy: 0.9964 - val_loss: 8.1861 - val_accuracy: 0.6793\n",
            "Epoch 928/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0075 - accuracy: 0.9964 - val_loss: 8.2077 - val_accuracy: 0.6848\n",
            "Epoch 929/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 8.1778 - val_accuracy: 0.6848\n",
            "Epoch 930/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 8.2088 - val_accuracy: 0.6848\n",
            "Epoch 931/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 0.9964 - val_loss: 8.2062 - val_accuracy: 0.6848\n",
            "Epoch 932/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 8.1741 - val_accuracy: 0.6848\n",
            "Epoch 933/1000\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0078 - accuracy: 0.9964 - val_loss: 8.2200 - val_accuracy: 0.6848\n",
            "Epoch 934/1000\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.0074 - accuracy: 0.9964 - val_loss: 8.2262 - val_accuracy: 0.6848\n",
            "Epoch 935/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 8.1967 - val_accuracy: 0.6848\n",
            "Epoch 936/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 8.2166 - val_accuracy: 0.6848\n",
            "Epoch 937/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 0.9964 - val_loss: 8.2450 - val_accuracy: 0.6848\n",
            "Epoch 938/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0076 - accuracy: 0.9964 - val_loss: 8.2177 - val_accuracy: 0.6848\n",
            "Epoch 939/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 8.2311 - val_accuracy: 0.6848\n",
            "Epoch 940/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0074 - accuracy: 0.9964 - val_loss: 8.2434 - val_accuracy: 0.6848\n",
            "Epoch 941/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 0.9964 - val_loss: 8.2387 - val_accuracy: 0.6793\n",
            "Epoch 942/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0077 - accuracy: 0.9964 - val_loss: 8.2347 - val_accuracy: 0.6848\n",
            "Epoch 943/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.9964 - val_loss: 8.2233 - val_accuracy: 0.6848\n",
            "Epoch 944/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 8.2621 - val_accuracy: 0.6848\n",
            "Epoch 945/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 8.2608 - val_accuracy: 0.6848\n",
            "Epoch 946/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 8.2022 - val_accuracy: 0.6848\n",
            "Epoch 947/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 8.2862 - val_accuracy: 0.6902\n",
            "Epoch 948/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 8.2685 - val_accuracy: 0.6848\n",
            "Epoch 949/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 8.2665 - val_accuracy: 0.6848\n",
            "Epoch 950/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 8.2711 - val_accuracy: 0.6848\n",
            "Epoch 951/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9964 - val_loss: 8.2581 - val_accuracy: 0.6793\n",
            "Epoch 952/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 0.9964 - val_loss: 8.2980 - val_accuracy: 0.6848\n",
            "Epoch 953/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 8.2667 - val_accuracy: 0.6848\n",
            "Epoch 954/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 8.2898 - val_accuracy: 0.6793\n",
            "Epoch 955/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9928 - val_loss: 8.1753 - val_accuracy: 0.6739\n",
            "Epoch 956/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0092 - accuracy: 0.9964 - val_loss: 8.2944 - val_accuracy: 0.6848\n",
            "Epoch 957/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 8.2995 - val_accuracy: 0.6739\n",
            "Epoch 958/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 8.3013 - val_accuracy: 0.6848\n",
            "Epoch 959/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 8.2859 - val_accuracy: 0.6793\n",
            "Epoch 960/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 0.9964 - val_loss: 8.2780 - val_accuracy: 0.6848\n",
            "Epoch 961/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 8.3198 - val_accuracy: 0.6739\n",
            "Epoch 962/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 8.2988 - val_accuracy: 0.6793\n",
            "Epoch 963/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.9964 - val_loss: 8.2900 - val_accuracy: 0.6848\n",
            "Epoch 964/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 0.9964 - val_loss: 8.3158 - val_accuracy: 0.6902\n",
            "Epoch 965/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0076 - accuracy: 0.9964 - val_loss: 8.3005 - val_accuracy: 0.6793\n",
            "Epoch 966/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 0.9964 - val_loss: 8.2735 - val_accuracy: 0.6739\n",
            "Epoch 967/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 8.4142 - val_accuracy: 0.6848\n",
            "Epoch 968/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - accuracy: 0.9928 - val_loss: 8.3091 - val_accuracy: 0.6848\n",
            "Epoch 969/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 8.2751 - val_accuracy: 0.6793\n",
            "Epoch 970/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 0.9964 - val_loss: 8.3634 - val_accuracy: 0.6793\n",
            "Epoch 971/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - accuracy: 0.9964 - val_loss: 8.3519 - val_accuracy: 0.6848\n",
            "Epoch 972/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 8.3120 - val_accuracy: 0.6848\n",
            "Epoch 973/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 8.3186 - val_accuracy: 0.6739\n",
            "Epoch 974/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 8.3280 - val_accuracy: 0.6793\n",
            "Epoch 975/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 8.3552 - val_accuracy: 0.6848\n",
            "Epoch 976/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 0.9964 - val_loss: 8.3446 - val_accuracy: 0.6848\n",
            "Epoch 977/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 8.3631 - val_accuracy: 0.6902\n",
            "Epoch 978/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 8.3387 - val_accuracy: 0.6793\n",
            "Epoch 979/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 8.4001 - val_accuracy: 0.6793\n",
            "Epoch 980/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 8.3328 - val_accuracy: 0.6739\n",
            "Epoch 981/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 8.3780 - val_accuracy: 0.6848\n",
            "Epoch 982/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.9964 - val_loss: 8.3853 - val_accuracy: 0.6848\n",
            "Epoch 983/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 8.3561 - val_accuracy: 0.6793\n",
            "Epoch 984/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 8.4045 - val_accuracy: 0.6793\n",
            "Epoch 985/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 8.3659 - val_accuracy: 0.6793\n",
            "Epoch 986/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 8.3812 - val_accuracy: 0.6793\n",
            "Epoch 987/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 8.4966 - val_accuracy: 0.6739\n",
            "Epoch 988/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0080 - accuracy: 0.9964 - val_loss: 8.4678 - val_accuracy: 0.6739\n",
            "Epoch 989/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 0.9964 - val_loss: 8.3941 - val_accuracy: 0.6685\n",
            "Epoch 990/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0072 - accuracy: 0.9964 - val_loss: 8.3606 - val_accuracy: 0.6685\n",
            "Epoch 991/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 0.9964 - val_loss: 8.3917 - val_accuracy: 0.6739\n",
            "Epoch 992/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 8.4758 - val_accuracy: 0.6793\n",
            "Epoch 993/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 8.3641 - val_accuracy: 0.6793\n",
            "Epoch 994/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.9964 - val_loss: 8.3855 - val_accuracy: 0.6793\n",
            "Epoch 995/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 8.3740 - val_accuracy: 0.6793\n",
            "Epoch 996/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.9964 - val_loss: 8.4253 - val_accuracy: 0.6793\n",
            "Epoch 997/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 8.4161 - val_accuracy: 0.6793\n",
            "Epoch 998/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 8.4162 - val_accuracy: 0.6793\n",
            "Epoch 999/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 8.4383 - val_accuracy: 0.6793\n",
            "Epoch 1000/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 0.9964 - val_loss: 8.4686 - val_accuracy: 0.6739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80o1i3fzZsA-"
      },
      "source": [
        "**11. Plot the training loss and accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        " \n",
        "epochs = range(len(acc))\n",
        " \n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('custom_trainvalacc.png')\n",
        "plt.figure()\n",
        " \n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        " \n",
        "#plt.show()\n",
        "plt.savefig('custom_trainvalloss.png')\n",
        "plt.figure()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "69dOEi6HAiXT",
        "outputId": "9cb1174c-f169-4e39-b58b-7c5d1d9106f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8fUXoqeZvwf"
      },
      "source": [
        "**12. Evaluate the performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wawHhkURYMLE",
        "outputId": "8f8c24ec-01c5-47d8-9c08-5b910000807b"
      },
      "source": [
        "res =model.evaluate(X_testing, Y_testing)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 7.2097 - accuracy: 0.6981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WCSw36oZyG_"
      },
      "source": [
        "**13. Predict on new datatset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcE27mGFYo3G",
        "outputId": "809ffe10-c29c-4990-e1f5-39917377209a"
      },
      "source": [
        "test=X_testing[0]\n",
        "y_act=Y_testing[0]\n",
        "result=model.predict(test.reshape(1,8))\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.45582914, 0.54417086]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4RDC-ZHYqv_",
        "outputId": "bd9724db-09c4-4435-e3a0-68b64721fd10"
      },
      "source": [
        "import numpy as np\n",
        "y_pred = np.round(result)\n",
        "print(\"Actual:\"+ str(y_act))\n",
        "print(\"Predicted:\"+str(y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual:[1. 0.]\n",
            "Predicted:[[0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9mMqJtXYz2Q"
      },
      "source": [
        "**Reference:** - https://keras.io/"
      ]
    }
  ]
}